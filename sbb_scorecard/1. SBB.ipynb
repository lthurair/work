{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBB.py program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/sharb24/SBB/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### FIRST PROCESS THE GROSS VOLUME SEGMENTATION METRICS###########################################\n",
    "cred_fil=spark.sql(\"select * from anp_cabbtdct1_final.psa_elig_amsb\")\n",
    "cred_sbb_filter=cred_fil.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "cred_sbb_filter=cred_sbb_filter.astype({\"psa_month\": int})\n",
    "import calendar\n",
    "cred_sbb_filter['psa_month'] = cred_sbb_filter['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "#cred_sbb_filter.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding CLCP sideloaded data, to be appended to PSA data\n",
    "\n",
    "CLCP=spark.sql(\"select * from anp_cabbtdct1_sandbox.CLCP_S680\")\n",
    "CLCP_S680=CLCP.toPandas()\n",
    "#CLCP_S680.head(2)\n",
    "CLCP_S680['loanIssuedDate'] = pd.to_datetime(CLCP_S680['loanIssuedDate'])\n",
    "CLCP_S680['psa_month'] = (CLCP_S680['loanIssuedDate'].dt.month).apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "CLCP_S680['elig_ind']= 1\n",
    "CLCP_S680['seg_ind']= 1\n",
    "CLCP_S680['product_code']= 'S680'\n",
    "CLCP_S680['metric_name']= 'SBB Credit Widgets - Deals <=$75M'\n",
    "CLCP_S680['record_date']= rec_date\n",
    "CLCP_S680['record_date']= CLCP_S680['record_date'].astype('int')\n",
    "CLCP_S680['loanAmount']= CLCP_S680['loanAmount'].astype('float')\n",
    "CLCP_S680 = CLCP_S680.rename(columns={'createdBy': 'pr_acf2', 'loanAmount': 'current_amount'})\n",
    "CLCP_S680 = CLCP_S680[['psa_month','metric_name','pr_acf2','elig_ind','seg_ind','product_code','current_amount','record_date']]\n",
    "##### Add HR Data to CLCP\n",
    "df1=spark.sql(\"select acf2_id,employee_name,am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by acf2_id order by record_date desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "hrm1=df1.toPandas()\n",
    "\n",
    "## merge dataframe to hrm\n",
    "CLCP_All=pd.merge(CLCP_S680,hrm1[['acf2_id','employee_name','am_cost_center','am_cost_center_name', \\\n",
    "                                'am_cost_center_full_name','sm_cost_center','sm_cost_center_name']],\n",
    "                   how=\"left\",left_on=['pr_acf2'],right_on=['acf2_id'],indicator=True)\n",
    "\n",
    "CLCP_All.drop('_merge', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge CLCP with PSA eligible sales\n",
    "frames = [cred_sbb_filter, CLCP_All]\n",
    "result = pd.concat(frames)\n",
    "result.fillna(0,inplace = True)\n",
    "cred_sbb_filter = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### subset for GROSS VOLUME SEGMENTATION METRICS AND REST OF PSA METRICS\n",
    "cred_sbb_filter0=cred_sbb_filter[(cred_sbb_filter.seg_ind!=0)]\n",
    "cred_sbb_filter00=filterfunc(cred_sbb_filter0)\n",
    "\n",
    "## create metric name for rest of psa metrics\n",
    "\n",
    "############################# GROSS VOLUME ###########################################\n",
    "## SBB TAB: TOTAL SBB GROSS VOLUME\n",
    "sbb_gross_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_all_tuple)]\n",
    "sbb_gross_filter=sbb_gross_filter.assign(metric_name='Total SBB Gross Volume')\n",
    "sbb_gross_filter=filterfunc(sbb_gross_filter)\n",
    "\n",
    "## SBB GROSS LOC VOLUME\n",
    "gross_loc_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_loc_tuple)]\n",
    "gross_loc_filter=gross_loc_filter.assign(metric_name='SBB Gross LOC Volume')\n",
    "gross_loc_filter=filterfunc(gross_loc_filter)\n",
    "\n",
    "## SBB GROSS LON VOLUME\n",
    "gross_lon_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_lon_tuple)]\n",
    "gross_lon_filter=gross_lon_filter.assign(metric_name='SBB Gross LON Volume')\n",
    "gross_lon_filter=filterfunc(gross_lon_filter)\n",
    "\n",
    "## SBB GROSS PROFESSIONAL STUDENT LOC VOLUME\n",
    "gross_prof_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_student_loc_tuple)]\n",
    "gross_prof_filter=gross_prof_filter.assign(metric_name='Gross Professional Student LOC')\n",
    "gross_prof_filter=filterfunc(gross_prof_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "gross_all=pd.concat([sbb_gross_filter,gross_loc_filter,gross_lon_filter,gross_prof_filter],axis=0)\n",
    "\n",
    "########################## CREDIT CARDS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL CREDIT CARDS\n",
    "sbb_cc_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_cc_tuple)]\n",
    "sbb_cc_filter=sbb_cc_filter.assign(metric_name='Total Credit Cards')\n",
    "sbb_cc_filter=filterfunc(sbb_cc_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_bv_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_visa_cc_tuple)]\n",
    "sbb_bv_filter=sbb_bv_filter.assign(metric_name='Credit Cards - Business VISA')\n",
    "sbb_bv_filter=filterfunc(sbb_bv_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_btv_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_travel_tuple)]\n",
    "sbb_btv_filter=sbb_btv_filter.assign(metric_name='Credit Cards - Business Travel VISA')\n",
    "sbb_btv_filter=filterfunc(sbb_btv_filter)\n",
    "\n",
    "## SBB TAB: AEROPLAN BUSINESS\n",
    "sbb_aero_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_aero_tuple)]\n",
    "sbb_aero_filter=sbb_aero_filter.assign(metric_name='Credit Cards - Aeroplan Business')\n",
    "sbb_aero_filter=filterfunc(sbb_aero_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT NO FEE\n",
    "sbb_nofee_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(bus_nofee_tuple)]\n",
    "sbb_nofee_filter=sbb_nofee_filter.assign(metric_name='Credit Cards - Business Select No Fee')\n",
    "sbb_nofee_filter=filterfunc(sbb_nofee_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT FEE\n",
    "sbb_fee_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(bus_fee_tuple)]\n",
    "sbb_fee_filter=sbb_fee_filter.assign(metric_name='Credit Cards - Business Select Fee')\n",
    "sbb_fee_filter=filterfunc(sbb_fee_filter)\n",
    "\n",
    "## SBB TAB: CREDIT CARD INCREASES (CCI) - New product added\n",
    "sbb_cci_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_essentials_credit_card_increases)]\n",
    "sbb_cci_filter=sbb_cci_filter.assign(metric_name='Credit Cards Increases')\n",
    "sbb_cci_filter=filterfunc(sbb_cci_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "cc_all=pd.concat([sbb_cc_filter,sbb_bv_filter,sbb_btv_filter,sbb_aero_filter,\n",
    "                  sbb_nofee_filter,sbb_fee_filter,sbb_cci_filter],axis=0)\n",
    "\n",
    "########################## MERCHANT SOLUTIONS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL MERCHANT SOLUTIONS\n",
    "merchant_all=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_mer_tuple)]\n",
    "merchant_all=merchant_all.assign(metric_name='Total Merchant Solutions')\n",
    "merchant_all=filterfunc(merchant_all)\n",
    "\n",
    "################################ CMS ###############################################\n",
    "\n",
    "## SBB TAB: TOTAL CMS\n",
    "cms_all=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_cms_tuple)]\n",
    "cms_all=cms_all.assign(metric_name='Total Cash Management Services (including RDC)')\n",
    "cms_all=filterfunc(cms_all)\n",
    "\n",
    "################################ COMMERCIAL VOLUME ###################################\n",
    "\n",
    "## SBB TAB: TOTAL COMMERCIAL VOLUME\n",
    "sbb_com_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_com_tuple)]\n",
    "sbb_com_filter=sbb_com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "sbb_com_filter=filterfunc(sbb_com_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "sbb_dep_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(com_deposit_tuple)]\n",
    "sbb_dep_filter=sbb_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "sbb_dep_filter=filterfunc(sbb_dep_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL LOAN VOLUME\n",
    "sbb_loan_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(com_loan_tuple)]\n",
    "sbb_loan_filter=sbb_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "sbb_loan_filter=filterfunc(sbb_loan_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all=pd.concat([sbb_com_filter,sbb_dep_filter,sbb_loan_filter],axis=0)\n",
    "\n",
    "################################ NEW ACCOUNT OPENINGS ###############################\n",
    "\n",
    "## SBB TAB: TOTAL ACCOUNT OPENINGS\n",
    "sbb_open_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_new_tuple)]\n",
    "sbb_open_filter=sbb_open_filter.assign(metric_name='Total New SBB Chequing Accounts')\n",
    "sbb_open_filter=filterfunc(sbb_open_filter)\n",
    "\n",
    "## SBB TAB: GIC -- New product added\n",
    "sbb_gic_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gic_sbb)]\n",
    "sbb_gic_filter=sbb_gic_filter.assign(metric_name='GICs')\n",
    "sbb_gic_filter=filterfunc(sbb_gic_filter)\n",
    "\n",
    "################################ TD SECURITIES DIRECT TRADE ###########################\n",
    "\n",
    "## SBB TAB: TOTAL TD SECURITIES DIRECT TRADE\n",
    "sbb_trade_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_trade_tuple)]\n",
    "sbb_trade_filter=sbb_trade_filter.assign(metric_name='TD Securities Direct Trade')\n",
    "sbb_trade_filter=filterfunc(sbb_trade_filter)\n",
    "\n",
    "################################ BCP WIDGETS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL BCP WIDGETS\n",
    "sbb_bcp_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_bcp_tuple)]\n",
    "sbb_bcp_filter=sbb_bcp_filter.assign(metric_name='Business Credit Protection(BCP) Widgets')\n",
    "sbb_bcp_filter=filterfunc(sbb_bcp_filter)\n",
    "\n",
    "############################# MUR MORTGAGE VOLUME######################################\n",
    "\n",
    "## SBB TAB: MUR MORTGAGE VOLUME\n",
    "sbb_mur_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_mur_tuple)]\n",
    "sbb_mur_filter=sbb_mur_filter.assign(metric_name='Total MUR Mortgage Volume')\n",
    "sbb_mur_filter=filterfunc(sbb_mur_filter)\n",
    "\n",
    "################################ WEALTH REFERRAL WIDGETS #############################\n",
    "\n",
    "## SBB TAB: WEALTH REFERRAL WIDGETS\n",
    "sbb_wealth_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_wealth_tuple)]\n",
    "sbb_wealth_filter=sbb_wealth_filter.assign(metric_name='Total Wealth Referrals')\n",
    "sbb_wealth_filter=filterfunc(sbb_wealth_filter)\n",
    "\n",
    "########################################### BODP ############################################\n",
    "\n",
    "## SBB TAB: BODP\n",
    "sbb_bodp_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_bodp_tuple)]\n",
    "sbb_bodp_filter=sbb_bodp_filter.assign(metric_name='Total BODP')\n",
    "sbb_bodp_filter=filterfunc(sbb_bodp_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added sbb_gic_filter in psa_wid\n",
    "#sbb_mur_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# COUNT WIDGETS FOR AMSB ####################################\n",
    "\n",
    "## CONCATENATE WIDGETS DATAFRAMES (GROSS SEG,CREDIT CARDS,MERCHANT,CMS,ACCOUNT OPENINGS, TD SECURITIES,BCP,WEALTH,BODP)\n",
    "psa_wid=pd.concat([cred_sbb_filter00,cc_all,merchant_all,cms_all,sbb_open_filter,sbb_trade_filter,\n",
    "                     sbb_bcp_filter,sbb_wealth_filter,sbb_bodp_filter,sbb_gic_filter],axis=0)\n",
    "\n",
    "##(1) group to count all metrics (do not include cc because AMSBs could move)\n",
    "amsb_cred=psa_wid.groupby(by=['pr_acf2','psa_month','metric_name','record_date'],as_index=False).aggregate({\n",
    "                    'elig_ind': 'sum'\n",
    "                     })\n",
    "amsb_cred.rename(columns = {\"elig_ind\":'current_amount'}, inplace = True)\n",
    "amsb_cred=amsb_cred[['pr_acf2','psa_month','metric_name','current_amount','record_date']]\n",
    "\n",
    "## create Total metric for Gross Widgets (sum of Segmentation metrics)\n",
    "##(a) subset the segmentation metrics\n",
    "cred_sbb_filter01=cred_sbb_filter00[cred_sbb_filter00.metric_name.isin(gross_seg_tuple)]\n",
    "\n",
    "cred_sbb_filter01['metric_name']='Total SBB Credit Widgets'\n",
    "\n",
    "amsb_seg=cred_sbb_filter01.groupby(by=['pr_acf2','psa_month','metric_name','record_date'],as_index=False).aggregate({\n",
    "                    'seg_ind': 'sum'\n",
    "                     })\n",
    "amsb_seg.rename(columns = {\"seg_ind\":'current_amount'}, inplace = True)\n",
    "amsb_seg=amsb_seg[['pr_acf2','psa_month','metric_name','current_amount','record_date']]\n",
    "\n",
    "## concatenate the dataframes\n",
    "amsb_all99=pd.concat([amsb_cred,amsb_seg],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding a pseudo PSA file with 5 missing product codes\n",
    "#### Do only for 1-2 weeks of Nov\n",
    "#credr=spark.sql(\"select * from anp_cabbtdct1_sandbox.p_psa_elig_retail where product_code in {}\".format(tuple(total_com_tuple)))\n",
    "#credr_filter=credr.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "#credr_filter=credr_filter.astype({\"psa_month\": int,\"branch_no\": int,\"current_amount\": int,\"seg_ind\":int})\n",
    "#import calendar\n",
    "#credr_filter['psa_month'] = credr_filter['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "#cred_filter.head(10)\n",
    "#cred_sbb_filter = pd.concat([cred_sbb_filter, cred_filter], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debug cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_retail_buddy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# PROCESS RETAIL COMMERCIAL VOLUME FOR AMSB ################################\n",
    "## read in retail file\n",
    "df_com_fil=spark.sql(\"select * from anp_cabbtdct1_final.psa_elig_retail where product_code in {}\".format(tuple(total_com_tuple)))\n",
    "df_com_volume=df_com_fil.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "df_com_volume=df_com_volume.astype({\"psa_month\": int})\n",
    "import calendar\n",
    "df_com_volume['psa_month'] = df_com_volume['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "\n",
    "#### IMPORTANT - Uncomment line above when actual data is available\n",
    "######## Adding pseudo PSA retail for 5 missing products. Run only for 102 weeks of November\n",
    "#df_com_volume = pd.concat([df_com_volume, credr_filter], axis=0)\n",
    "########\n",
    "\n",
    "######################## CATEGORIZE between loan and deposit and total#############################################\n",
    "com_filter=df_com_volume[df_com_volume.product_code.isin(total_com_tuple)]\n",
    "com_filter=com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "com_filter1=com_filter[['branch_no','psa_month','metric_name','current_amount','record_date']]\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "com_dep_filter=df_com_volume[df_com_volume.product_code.isin(com_deposit_tuple)]\n",
    "com_dep_filter=com_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "com_dep_filter1=com_dep_filter[['branch_no','psa_month','metric_name','current_amount','record_date']]\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL LOAN VOLUME\n",
    "com_loan_filter=df_com_volume[df_com_volume.product_code.isin(com_loan_tuple)]\n",
    "com_loan_filter=com_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "com_loan_filter1=com_loan_filter[['branch_no','psa_month','metric_name','current_amount','record_date']]\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all_ret=pd.concat([com_filter1,com_dep_filter1,com_loan_filter1],axis=0)\n",
    "########****** Below 2 lines added for Nov 3\n",
    "com_all_ret['branch_no'] = com_all_ret['branch_no'].astype('int')\n",
    "com_all_ret['current_amount'] = com_all_ret['current_amount'].astype('int')\n",
    "\n",
    "####################### read in buddy branch (for AMSB) ###########################\n",
    "df_bud_max=spark.sql(\"select branch,logon,mon from \\\n",
    "(select branch,logon,cast(SUBSTR(record_date,5,2) as int) as mon, record_date, \\\n",
    "row_number() over(partition by branch,cast(SUBSTR(record_date,5,2) as int) order by record_date desc) as ran \\\n",
    "from anp_cabbtdct1_final.buddy_branch)b where ran=1\")\n",
    "buddy_branch=df_bud_max.toPandas()\n",
    "\n",
    "buddy_branch=buddy_branch.astype({\"mon\": int})\n",
    "import calendar\n",
    "buddy_branch['mon'] = buddy_branch['mon'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "\n",
    "########****** Below 2 lines added for Nov 3\n",
    "#credr_filter['branch_no'] = credr_filter['branch_no'].astype('int')\n",
    "#buddy_branch['branch'] = buddy_branch['branch'].astype('int')\n",
    "## merge COM dataframe to buddy branch file\n",
    "df_retail_buddy=pd.merge(com_all_ret,buddy_branch[['branch','logon','mon']],\n",
    "                   how=\"left\",left_on=['branch_no','psa_month'],right_on=['branch','mon'],indicator=True)\n",
    "\n",
    "## filter both records\n",
    "df_retail_buddy1=df_retail_buddy[(df_retail_buddy['_merge'] == 'both')]\n",
    "\n",
    "## rename\n",
    "df_retail_buddy1.rename(columns = {\"logon\":'pr_acf2'}, inplace = True)\n",
    "\n",
    "## keep relevant vars\n",
    "df_retail_buddy2=df_retail_buddy1[['pr_acf2','psa_month','metric_name','current_amount','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# SUM VOLUME (for AMSBs) ####################################\n",
    "\n",
    "## CONCATENATE VOLUME DATAFRAMES (GROSS VOLUME (SBB),COMMERCIAL VOLUME (SBB AND RETAIL), MUR VOLUME) ---THIS IS FOR AMSB ONLY\n",
    "## AM AND SM RETAIL COMMERCIAL VOLUME IS CALCULATED SEPARATELY\n",
    "gross_all1=gross_all[['pr_acf2','psa_month','metric_name','current_amount','record_date']] ################ Gross Volume (SBB filter)\n",
    "com_all1=com_all[['pr_acf2','psa_month','metric_name','current_amount','record_date']] ################# Comm Volume (SBB filter)\n",
    "sbb_mur_filter1=sbb_mur_filter[['pr_acf2','psa_month','metric_name','current_amount','record_date']] ######### MUR volume (SBB filter)\n",
    "#Removed df_retail_buddy2\n",
    "psa_vol=pd.concat([gross_all1,com_all1,df_retail_buddy2,sbb_mur_filter1],axis=0)\n",
    "#psa_vol=pd.concat([gross_all1,com_all1,sbb_mur_filter1],axis=0)\n",
    "\n",
    "## group to count\n",
    "psa_vol['current_amount'] = psa_vol['current_amount'].astype('float')\n",
    "psa_vol1=psa_vol.groupby(by=['pr_acf2','psa_month','metric_name','record_date'],as_index=False).aggregate({\n",
    "                    'current_amount': 'sum'\n",
    "                     })\n",
    "\n",
    "## re-order vars\n",
    "psa_vol1=psa_vol1[['pr_acf2','psa_month','metric_name','current_amount','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### concatenate the widgets and volume dataframes -----------THIS IS FOR AMSB ONLY (because it contains retail com vol. for amsb)\n",
    "amsb_tot=pd.concat([amsb_all99,psa_vol1],axis=0)\n",
    "\n",
    "##transpose data\n",
    "psa_vol2=amsb_tot.pivot_table(index=['pr_acf2','metric_name','record_date'], columns=['psa_month'],\n",
    "                     values='current_amount', aggfunc='first').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "## get AMSB's AM CC and SM CC Names\n",
    "df=spark.sql(\"select acf2_id,employee_name,am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by acf2_id order by record_date desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "hrm=df.toPandas()\n",
    "\n",
    "## merge dataframe to hrm\n",
    "hrm_all=pd.merge(psa_vol2,hrm[['acf2_id','employee_name','am_cost_center','am_cost_center_name', \\\n",
    "                                'am_cost_center_full_name','sm_cost_center','sm_cost_center_name']],\n",
    "                   how=\"left\",left_on=['pr_acf2'],right_on=['acf2_id'],indicator=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATE ALL OF THE MONTHS\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in hrm_all]\n",
    "\n",
    "hrm_all.reset_index(drop=True, inplace=True)\n",
    "amsb_cred2= pd.concat([net_a[complementary], hrm_all], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "amsb_cred2= amsb_cred2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "amsb_cred2 = amsb_cred2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "amsb_cred2=amsb_cred2.drop(columns=['acf2_id'])\n",
    "amsb_cred2.rename(columns = {\"pr_acf2\":'acf2_id'}, inplace = True)\n",
    "amsb_cred2['scorecard_filter']='SBB'\n",
    "amsb_cred2['level']='AMSB'\n",
    "\n",
    "## order relevant vars for AMSB\n",
    "amsb_cred6=amsb_cred2[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW create QTD and YTD variables\n",
    "newvarfunc(amsb_cred6)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "amsb_cred6=amsb_cred6.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_amsb_median=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_amsb_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all3=pd.merge(amsb_cred6,cred_amsb_median,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_amsb_median1=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_amsb_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all4=pd.merge(cred_amsb_all3,cred_amsb_median1,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_amsb_median2=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_amsb_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all5=pd.merge(cred_amsb_all4,cred_amsb_median2,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_amsb_median3=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_amsb_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all6=pd.merge(cred_amsb_all5,cred_amsb_median3,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_amsb_ytdmedian=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_amsb_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all7=pd.merge(cred_amsb_all6,cred_amsb_ytdmedian,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "cred_amsb_all8=cred_amsb_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "#cred_amsb_all8.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP for AM (SBB FILTER)##############################\n",
    "\n",
    "#### concatenate all SBB volume dataframes (does not include retail com volume; will be calculated for AM/SM in Retail program)\n",
    "psa_vol_am=pd.concat([gross_all,com_all,sbb_mur_filter],axis=0)\n",
    "\n",
    "## group to count (include acf2 because need to concatenate later with AMSB widgets df)\n",
    "psa_vol_am['current_amount']=psa_vol_am['current_amount'].astype('float')\n",
    "psa_vol1_am=psa_vol_am.groupby(by=['psa_month','metric_name','record_date','am_cost_center','am_cost_center_name',\n",
    "                                     'am_cost_center_full_name','sm_cost_center','sm_cost_center_name'],as_index=False).aggregate({\n",
    "                    'current_amount': 'sum'\n",
    "                     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## COUNT WIDGETS FOR AM ####################################\n",
    "\n",
    "## CONCATENATE WIDGETS DATAFRAMES (GROSS SEG,CREDIT CARDS,MERCHANT,CMS,ACCOUNT OPENINGS, TD SECURITIES,BCP,WEALTH,BODP)\n",
    "psa_wid=pd.concat([cred_sbb_filter00,cc_all,merchant_all,cms_all,sbb_open_filter,sbb_trade_filter,\n",
    "                     sbb_bcp_filter,sbb_wealth_filter,sbb_bodp_filter],axis=0)\n",
    "\n",
    "##(1) group to count all metrics (do not include AMSBs because AMSBs could move)\n",
    "am_cred=psa_wid.groupby(by=['psa_month','metric_name','record_date','am_cost_center','am_cost_center_name',\n",
    "                              'am_cost_center_full_name','sm_cost_center','sm_cost_center_name'],as_index=False).aggregate({\n",
    "                    'elig_ind': 'sum'\n",
    "                     })\n",
    "am_cred.rename(columns = {\"elig_ind\":'current_amount'}, inplace = True)\n",
    "\n",
    "\n",
    "## create Total metric for Gross Widgets (sum of Segmentation metrics)\n",
    "##(a) subset the segmentation metrics\n",
    "cred_sbb_filter01=cred_sbb_filter00[cred_sbb_filter00.metric_name.isin(gross_seg_tuple)]\n",
    "\n",
    "cred_sbb_filter01['metric_name']='Total SBB Credit Widgets'\n",
    "\n",
    "am_seg=cred_sbb_filter01.groupby(by=['psa_month','metric_name','record_date','am_cost_center','am_cost_center_name',\n",
    "                                     'am_cost_center_full_name','sm_cost_center','sm_cost_center_name'],as_index=False).aggregate({\n",
    "                    'elig_ind': 'sum'\n",
    "                     })\n",
    "am_seg.rename(columns = {\"elig_ind\":'current_amount'}, inplace = True)\n",
    "\n",
    "## concatenate the dataframes\n",
    "am_all99=pd.concat([am_cred,am_seg],axis=0)\n",
    "\n",
    "### concatenate the widgets and volume (does not include retail com vol.)\n",
    "psa_all_am=pd.concat([am_all99,psa_vol1_am],axis=0)\n",
    "\n",
    "\n",
    "##transpose data\n",
    "psa_all2_am=psa_all_am.pivot_table(index=['metric_name','record_date','am_cost_center','am_cost_center_name',\n",
    "                                     'am_cost_center_full_name','sm_cost_center','sm_cost_center_name'], columns=['psa_month'],\n",
    "                     values='current_amount', aggfunc='first').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATE ALL OF THE MONTHS\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in psa_all2_am]\n",
    "\n",
    "psa_all2_am.reset_index(drop=True, inplace=True)\n",
    "psa_all_am2= pd.concat([net_a[complementary], psa_all2_am], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "psa_all_am2= psa_all_am2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "psa_all_am2 = psa_all_am2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## group by AM ##########################################\n",
    "cred_am=amgrpfunc(psa_all_am2)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_am['level']='AM'\n",
    "cred_am['scorecard_filter']='SBB'\n",
    "cred_am['acf2_id']=''\n",
    "cred_am['employee_name']=cred_am['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_am)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_am=cred_am.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_am_median=cred_am.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all3=pd.merge(cred_am,cred_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_am_median1=cred_am.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all4=pd.merge(cred_am_all3,cred_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_am_median2=cred_am.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all5=pd.merge(cred_am_all4,cred_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_am_median3=cred_am.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all6=pd.merge(cred_am_all5,cred_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_am_ytdmedian=cred_am.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all7=pd.merge(cred_am_all6,cred_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_am_all8=cred_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY SM (SBB FILTER)##############################\n",
    "cred_sm=smgrpfunc(cred_am_all8)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_sm['level']='SM'\n",
    "cred_sm['acf2_id']=''\n",
    "cred_sm['scorecard_filter']='SBB'\n",
    "cred_sm['employee_name']=cred_sm['sm_cost_center_name']\n",
    "cred_sm['am_cost_center']=''\n",
    "cred_sm['am_cost_center_name']=''\n",
    "cred_sm['am_cost_center_full_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_sm)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_sm=cred_sm.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_sm_median=cred_sm.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all3=pd.merge(cred_sm,cred_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_sm_median1=cred_sm.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all4=pd.merge(cred_sm_all3,cred_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_sm_median2=cred_sm.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all5=pd.merge(cred_sm_all4,cred_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_sm_median3=cred_sm.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all6=pd.merge(cred_sm_all5,cred_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_sm_ytdmedian=cred_sm.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all7=pd.merge(cred_sm_all6,cred_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_sm_all8=cred_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### concatenate AMSB, AM, SM\n",
    "df_sbb_all=pd.concat([cred_amsb_all8,cred_am_all8,cred_sm_all8],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all = df_sbb_all.astype({\"metric_name\":str,\"level\":str,\"acf2_id\":str,\"employee_name\":str,\"am_cost_center\":str,\n",
    "                               \"am_cost_center_name\":str, \"am_cost_center_full_name\":str, \"sm_cost_center\":str,\n",
    "                               \"sm_cost_center_name\":str,\"record_date\":str})\n",
    "#df_sbb_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(df_sbb_all).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_METRICS_SBB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM\n",
    "df_sbb_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all = df_sbb_all.astype({\"metric_name\":str,\"level\":str,\"acf2_id\":str,\"employee_name\":str,\"am_cost_center\":str,\n",
    "                               \"am_cost_center_name\":str, \"am_cost_center_full_name\":str, \"sm_cost_center\":str,\n",
    "                               \"sm_cost_center_name\":str,\"record_date\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
