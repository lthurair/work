{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BRANCH ADOPTION.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/sharb24/SBB/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "############################### BRANCH ADOPTION ###################################################\n",
    "\n",
    "## this only pulls weekly data\n",
    "dfbr=spark.table('anp_cabbtdct1_final.SBB_BRANCH_ADOPTION') \n",
    "df_br=dfbr.toPandas()\n",
    "\n",
    "df_br1=df_br[(df_br.record_date>=fy_start) & (df_br.record_date<=rec_date)]\n",
    "\n",
    "## add a new record_date variable\n",
    "EDPP5=df_br1.copy()\n",
    "\n",
    "EDPP5['month_dt'] = pd.to_datetime(EDPP5.prdate, format='%Y-%m-%d')\n",
    "EDPP5['month_dt'] = EDPP5['month_dt'].dt.month\n",
    "\n",
    "###### EXTRACT THE BBS AND RETAIL\n",
    "EDPP5=EDPP5[(EDPP5.jobcode=='BBS') | (EDPP5.jobcode=='Retail')]\n",
    "\n",
    "EDPP5.rename(columns = {\"booking_transit\":'branch'}, inplace = True)\n",
    "EDPP5['branch']=EDPP5['branch'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge to alignment\n",
    "df3=spark.sql(\"select branch, am_cost_center, am_cost_center_name, sm_cost_center, sm_cost_center_name, \\\n",
    "    mon, case when AM_Cost_Center='3838' then '3838 - RAMSB' when AM_Cost_Center='5311' then '5311 - RAMSB' \\\n",
    "    else concat(AM_Cost_Center,' - ',AM_Cost_Center_Name) end as am_cost_center_full_name \\\n",
    "    from \\\n",
    "    (select branch,AM_Cost_Center, AM_Cost_Center_Name,SM_Cost_Center,SM_Cost_Center_Name, \\\n",
    "    record_date,cast(SUBSTR(record_date,5,2) as int) as mon, \\\n",
    "    row_number() over(partition by branch,cast(SUBSTR(record_date,5,2) as int) order by record_date desc) as ran \\\n",
    "    from anp_cabbtdct1_final.sbb_alignment \\\n",
    "    )n where ran=1\")\n",
    "df2=df3.withColumn(\"branch_0000\",format_string(\"%04d\",\"branch\"))\n",
    "dfsbb=df2.toPandas()\n",
    "\n",
    "adopt00=pd.merge(EDPP5,dfsbb, left_on=['branch','month_dt'],right_on=['branch_0000','mon'],how=\"left\")\n",
    "\n",
    "import calendar\n",
    "adopt00['month_dt'] = adopt00['month_dt'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "\n",
    "##rename branch\n",
    "adopt00.rename(columns = {\"branch_0000\":'branch'}, inplace = True)\n",
    "\n",
    "### group by job_code (BBS or Retail) and sum up by distinct trxn id\n",
    "    ##keep only relevant variables\n",
    "adopt1=adopt00[['transaction_id','jobcode','branch','am_cost_center', 'am_cost_center_name','am_cost_center_full_name',\n",
    "              'sm_cost_center','sm_cost_center_name','month_dt']].drop_duplicates()\n",
    "    \n",
    "adopt2=adopt1.groupby(by=['jobcode','am_cost_center', 'am_cost_center_name','am_cost_center_full_name',\n",
    "              'sm_cost_center','sm_cost_center_name','month_dt'],as_index=False).aggregate({\n",
    "                    'transaction_id': 'nunique'\n",
    "                     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate BBS from Retail and then divide to get branch adoption rate\n",
    "##BBS\n",
    "bbs_adopt=adopt2[(adopt2.jobcode=='BBS')]\n",
    "bbs_adopt.rename(columns = {\"jobcode\":'jobcode_BBS', \"transaction_id\":'bbs_count'}, inplace = True)\n",
    "\n",
    "##Retail\n",
    "retail_adopt=adopt2[(adopt2.jobcode=='Retail')]\n",
    "retail_adopt.rename(columns = {\"jobcode\":'jobcode_Retail', \"transaction_id\":'retail_count'}, inplace = True)\n",
    "\n",
    "## remove un-wanted vars from Retail\n",
    "retail_adopt.drop(columns=['sm_cost_center', 'sm_cost_center_name','am_cost_center_full_name','am_cost_center_name'])\n",
    "\n",
    "## merge the two\n",
    "adopt_full=pd.merge(bbs_adopt,retail_adopt, left_on=['month_dt','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                        'sm_cost_center','sm_cost_center_name'],\n",
    "                    right_on=['month_dt','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                        'sm_cost_center','sm_cost_center_name'],how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in with 0's\n",
    "adopt_full['bbs_count']=adopt_full['bbs_count'].fillna(0)\n",
    "adopt_full['retail_count']=adopt_full['retail_count'].fillna(0)\n",
    "\n",
    "## keep relevant vars\n",
    "adopt_full1=adopt_full[['am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                        'sm_cost_center','sm_cost_center_name','jobcode_Retail','retail_count',\n",
    "                        'jobcode_BBS','bbs_count', 'month_dt']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "##################################### CALCULATE BRANCH ADOPTION RATE ##########################################\n",
    "\n",
    "adopt_full1['Branch Adoption percent']=(adopt_full1.bbs_count/(adopt_full1.bbs_count+adopt_full1.retail_count))\n",
    "\n",
    "## include the metric name and scorecard date\n",
    "adopt_full1['metric_name']='Branch Adoption percent'\n",
    "\n",
    "#### transpose data\n",
    "a =adopt_full1.pivot_table(index=['am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                        'sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='Branch Adoption percent', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "## create a copy\n",
    "adopt_full3=adopt_full1.copy()\n",
    "## create a metric name\n",
    "adopt_full3['metric_name']='Branch Adoption new accounts'\n",
    "\n",
    "b =adopt_full3.pivot_table(index=['am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                        'sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='bbs_count', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##### append the two dataframes (2 metrics)\n",
    "adopt_all=pd.concat([a,b],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in adopt_all]\n",
    "\n",
    "adopt_all.reset_index(drop=False, inplace=True)\n",
    "adopt_new2= pd.concat([net_a[complementary], adopt_all], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "adopt_new2= adopt_new2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "adopt_new2=adopt_new2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "adopt_new2['q1'] = adopt_new2[['november','december','january']].mean(axis=1)\n",
    "adopt_new2['q2'] = adopt_new2[['february','march','april']].mean(axis=1)\n",
    "adopt_new2['q3'] = adopt_new2[['may','june','july']].mean(axis=1)\n",
    "adopt_new2['q4'] = adopt_new2[['august','september','october']].mean(axis=1)\n",
    "adopt_new2['ytd'] = adopt_new2[['november','december','january','february','march','april','may','june','july','august','september','october']].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace 0 with NaN so median only counts non-zeros\n",
    "adopt_new2=adopt_new2.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_am_medianq1=adopt_new2.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_am_medianq2=adopt_new2.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_am_medianq3=adopt_new2.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_am_medianq4=adopt_new2.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_am_medianytd=adopt_new2.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_am_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_am_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_am_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_am_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_am_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "adopta=pd.merge(pd.merge(adopt_new2,df_am_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "adoptb=pd.merge(pd.merge(adopta,df_am_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "adoptc=pd.merge(adoptb,df_am_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "adoptc['level']='AM'\n",
    "adoptc['scorecard_filter']='SBB'\n",
    "adoptc['employee_name']=adoptc.am_cost_center_full_name\n",
    "adoptc['acf2_id']=''\n",
    "adoptc['record_date']=rec_date\n",
    "\n",
    "### get AM\n",
    "adopt_am=adoptc[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "        'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "\n",
    "## create a copy for Total\n",
    "adopt_am1=adopt_am.copy()\n",
    "adopt_am1['scorecard_filter']='Total'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GROUP BY REGION_ID AND SUM UP\n",
    "#### transpose data\n",
    "a =adopt_full1.pivot_table(index=['sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='Branch Adoption percent', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "## create a copy\n",
    "adopt_full3=adopt_full1.copy()\n",
    "\n",
    "## create a metric name\n",
    "adopt_full3['metric_name']='Branch Adoption new accounts'\n",
    "\n",
    "b =adopt_full3.pivot_table(index=['sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='bbs_count', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##### append the two dataframes (2 metrics)\n",
    "adopt_all=pd.concat([a,b],axis=0)\n",
    "\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in adopt_all]\n",
    "\n",
    "adopt_all.reset_index(drop=False, inplace=True)\n",
    "sm_ad= pd.concat([net_a[complementary], adopt_all], axis=1, join='outer',sort=False)\n",
    "\n",
    "##delete the extra filler row\n",
    "sm_ad= sm_ad.drop(labels='a', axis=0)\n",
    "sm_ad= sm_ad.drop(columns='index', axis=0)\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in sm_ad]\n",
    "sm_ad2= pd.concat([net_a[complementary], sm_ad], axis=1, join='outer',sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### ROLL UP TO SM ##########################################\n",
    "\n",
    "## GROUP BY REGION_ID AND SUM UP\n",
    "#### transpose data\n",
    "a =adopt_full1.pivot_table(index=['sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='Branch Adoption percent', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "## create a copy\n",
    "adopt_full3=adopt_full1.copy()\n",
    "\n",
    "## create a metric name\n",
    "adopt_full3['metric_name']='Branch Adoption new accounts'\n",
    "\n",
    "b =adopt_full3.pivot_table(index=['sm_cost_center','sm_cost_center_name','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='bbs_count', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##### append the two dataframes (2 metrics)\n",
    "adopt_all=pd.concat([a,b],axis=0)\n",
    "\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in adopt_all]\n",
    "\n",
    "adopt_all.reset_index(drop=False, inplace=True)\n",
    "sm_ad= pd.concat([net_a[complementary], adopt_all], axis=1, join='outer',sort=False)\n",
    "\n",
    "##delete the extra filler row\n",
    "sm_ad= sm_ad.drop(labels='a', axis=0)\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in sm_ad]\n",
    "sm_ad2= pd.concat([net_a[complementary], sm_ad], axis=1, join='outer',sort=False)\n",
    "\n",
    "##delete the extra filler row\n",
    "sm_ad2= sm_ad2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "sm_ad2=sm_ad2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "sm_ad2['q1'] = sm_ad2[['november','december','january']].mean(axis=1)\n",
    "sm_ad2['q2'] = sm_ad2[['february','march','april']].mean(axis=1)\n",
    "sm_ad2['q3'] = sm_ad2[['may','june','july']].mean(axis=1)\n",
    "sm_ad2['q4'] = sm_ad2[['august','september','october']].mean(axis=1)\n",
    "sm_ad2['ytd'] = sm_ad2[['november','december','january','february','march','april','may','june','july','august','september','october']].mean(axis=1)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "sm_ad2=sm_ad2.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_sm_medianq1=sm_ad2.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_sm_medianq2=sm_ad2.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_sm_medianq3=sm_ad2.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_sm_medianq4=sm_ad2.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_sm_medianytd=sm_ad2.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_sm_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_sm_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_sm_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_sm_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_sm_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "sm_ad3=pd.merge(pd.merge(sm_ad2,df_sm_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "sm_ad4=pd.merge(pd.merge(sm_ad3,df_sm_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "sm_ad5=pd.merge(sm_ad4,df_sm_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "sm_ad5['acf2_id']=''\n",
    "sm_ad5['level']='SM'\n",
    "sm_ad5['scorecard_filter']='SBB'\n",
    "sm_ad5['employee_name']=sm_ad5.sm_cost_center_name\n",
    "sm_ad5['am_cost_center']=''\n",
    "sm_ad5['am_cost_center_name']=''\n",
    "sm_ad5['am_cost_center_full_name']=''\n",
    "sm_ad5['record_date']=rec_date\n",
    "\n",
    "sm_adopt=sm_ad5[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "        'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## make a copy for Total\n",
    "sm_adopt1=sm_adopt.copy()\n",
    "sm_adopt1['scorecard_filter']='Total'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#################################### ROLL UP TO NATIONAL OFFICE ###################################\n",
    "#### transpose data\n",
    "a =adopt_full1.pivot_table(index=['metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='Branch Adoption percent', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "## create a copy\n",
    "adopt_full3=adopt_full1.copy()\n",
    "\n",
    "## create a metric name\n",
    "adopt_full3['metric_name']='Branch Adoption new accounts'\n",
    "\n",
    "b =adopt_full3.pivot_table(index=['metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='bbs_count', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##### append the two dataframes (2 metrics)\n",
    "adopt_all=pd.concat([a,b],axis=0)\n",
    "\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in adopt_all]\n",
    "\n",
    "adopt_all.reset_index(drop=False, inplace=True)\n",
    "nso_ad= pd.concat([net_a[complementary], adopt_all], axis=1, join='outer',sort=False)\n",
    "\n",
    "##delete the extra filler row\n",
    "nso_ad= nso_ad.drop(labels='a', axis=0)\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in nso_ad]\n",
    "nso_ad2= pd.concat([net_a[complementary], nso_ad], axis=1, join='outer',sort=False)\n",
    "\n",
    "##delete the extra filler row\n",
    "nso_ad2= nso_ad2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "nso_ad2=nso_ad2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "nso_ad2['q1'] = nso_ad2[['november','december','january']].mean(axis=1)\n",
    "nso_ad2['q2'] = nso_ad2[['february','march','april']].mean(axis=1)\n",
    "nso_ad2['q3'] = nso_ad2[['may','june','july']].mean(axis=1)\n",
    "nso_ad2['q4'] = nso_ad2[['august','september','october']].mean(axis=1)\n",
    "nso_ad2['ytd'] = nso_ad2[['november','december','january','february','march','april','may','june','july','august','september','october']].mean(axis=1)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "nso_ad2=nso_ad2.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_nso_medianq1=nso_ad2.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_nso_medianq2=nso_ad2.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_nso_medianq3=nso_ad2.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_nso_medianq4=nso_ad2.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_nso_medianytd=nso_ad2.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_nso_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_nso_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_nso_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_nso_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_nso_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "nso_ad1=pd.merge(pd.merge(nso_ad2,df_nso_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "nso_ad0=pd.merge(pd.merge(nso_ad1,df_nso_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "nso_ad3=pd.merge(nso_ad0,df_nso_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "nso_ad3['acf2_id']=''\n",
    "nso_ad3['level']='National Office'\n",
    "nso_ad3['scorecard_filter']='Total'\n",
    "nso_ad3['employee_name']='National Office'\n",
    "nso_ad3['am_cost_center']=''\n",
    "nso_ad3['am_cost_center_name']=''\n",
    "nso_ad3['sm_cost_center']=''\n",
    "nso_ad3['sm_cost_center_name']=''\n",
    "nso_ad3['am_cost_center_full_name']=''\n",
    "nso_ad3['record_date']=rec_date\n",
    "\n",
    "nso_adopt=nso_ad3[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## CONCATENATE ALL DATAFRAMES ##############################################\n",
    "branch_adopt_all=pd.concat([adopt_am,adopt_am1,sm_adopt,sm_adopt1,nso_adopt],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_adopt_all.scorecard_filter.unique()\n",
    "branch_adopt_all.groupby(['level', 'scorecard_filter'], as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_adopt_all.record_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(branch_adopt_all).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_OUTPUT_BRANCH_ADOPTION\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
