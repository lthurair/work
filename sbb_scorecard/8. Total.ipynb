{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create \"Total\" (sum of SBB filter and Retail filter) for AMs and SMs, and Create National Office Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/sharb24/SBB/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# DEFINE VARIABLES ##############\n",
    "\n",
    "gnb_tup=('Total GNB Widgets (Actual)', 'GNB Points 1PT','GNB Points 4PTS','GNB Points 10PTS','GNB Points 12PTS','Total GNB Points',\n",
    "         'Total SBB Net Authorized Volume','SBB Net Authorized LON Volume','SBB Net Authorized LOC Volume','Net SBB Professional Banking',\n",
    "         'Net Professional Student LOC','Net Franchise Banking Net Volume','Net Professional Banking Net Volume',\n",
    "         'Net Professional and Franchise Banking')\n",
    "\n",
    "lei_tup=('LEI',)\n",
    "\n",
    "ctp_tup=('Contribution to Profit (CTP)',)\n",
    "\n",
    "tdef_tup=('TDEF Volume',)\n",
    "\n",
    "total_onetd=('Total Wealth Referrals','AMSB Retail Referrals','TD Securities Direct Trade')\n",
    "total_be=('Business Credit Protection(BCP) Widgets','Total Merchant Solutions','Total Cash Management Services (including RDC)',\n",
    "         'Total Credit Cards','Credit Cards Increases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in the sbb filter data\n",
    "sbb_filter=spark.sql(\"select * from anp_cabbtdct1_final.SBB_SC_METRICS_SBB\")\n",
    "sbb_filter0=sbb_filter.toPandas()\n",
    "sbb_filter0= sbb_filter0.astype({\"record_date\": int})\n",
    "sbb_filter0= sbb_filter0.astype({\"record_date\": str})\n",
    "sbb_filter1=sbb_filter0[(sbb_filter0.record_date==rec_date)]\n",
    "\n",
    "## read in the retail filter data\n",
    "retail_filter=spark.sql(\"select * from anp_cabbtdct1_final.SBB_SC_METRICS_RETAIL\")\n",
    "retail_filter0=retail_filter.toPandas()\n",
    "retail_filter0= retail_filter0.astype({\"record_date\": int})\n",
    "retail_filter0= retail_filter0.astype({\"record_date\": str})\n",
    "retail_filter1=retail_filter0[(retail_filter0.record_date==rec_date)]\n",
    "\n",
    "## concatenate the sbb and retail dataframes\n",
    "sbb_retail_all=pd.concat([sbb_filter1,retail_filter1],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbb_retail_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter AMSB for later concatenation\n",
    "sbb_amsb=sbb_retail_all[(sbb_retail_all.level=='AMSB')]\n",
    "\n",
    "## filter for AM\n",
    "sbb_am=sbb_retail_all[(sbb_retail_all.level=='AM')]\n",
    "\n",
    "## filter for SM\n",
    "sbb_sm=sbb_retail_all[(sbb_retail_all.level=='SM')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY AM ##############################\n",
    "tot_am=amgrpfunc(sbb_am)\n",
    "\n",
    "##include the LEVEL variable\n",
    "tot_am['level']='AM'\n",
    "tot_am['scorecard_filter']='Total'\n",
    "tot_am['acf2_id']=''\n",
    "tot_am['employee_name']=tot_am['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(tot_am)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "tot_am=tot_am.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "tot_am_median=tot_am.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "tot_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_am_all3=pd.merge(tot_am,tot_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "tot_am_median1=tot_am.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "tot_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_am_all4=pd.merge(tot_am_all3,tot_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "tot_am_median2=tot_am.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "tot_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_am_all5=pd.merge(tot_am_all4,tot_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "tot_am_median3=tot_am.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "tot_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_am_all6=pd.merge(tot_am_all5,tot_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "tot_am_ytdmedian=tot_am.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "tot_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_am_all7=pd.merge(tot_am_all6,tot_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "tot_am_all8=tot_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY SM ##############################\n",
    "tot_sm=smgrpfunc(sbb_sm)\n",
    "\n",
    "##include the LEVEL variable\n",
    "tot_sm['level']='SM'\n",
    "tot_sm['acf2_id']=''\n",
    "tot_sm['scorecard_filter']='Total'\n",
    "tot_sm['employee_name']=tot_sm['sm_cost_center_name']\n",
    "tot_sm['am_cost_center']=''\n",
    "tot_sm['am_cost_center_name']=''\n",
    "tot_sm['am_cost_center_full_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(tot_sm)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "tot_sm=tot_sm.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "tot_sm_median=tot_sm.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "tot_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_sm_all3=pd.merge(tot_sm,tot_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "tot_sm_median1=tot_sm.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "tot_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_sm_all4=pd.merge(tot_sm_all3,tot_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "tot_sm_median2=tot_sm.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "tot_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_sm_all5=pd.merge(tot_sm_all4,tot_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "tot_sm_median3=tot_sm.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "tot_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_sm_all6=pd.merge(tot_sm_all5,tot_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "tot_sm_ytdmedian=tot_sm.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "tot_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_sm_all7=pd.merge(tot_sm_all6,tot_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "tot_sm_all8=tot_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY NATIONAL OFFICE ##############################\n",
    "\n",
    "tot_nso=natgrpfunc(tot_sm_all8)\n",
    "\n",
    "##include the LEVEL variable\n",
    "tot_nso['level']='National Office'\n",
    "tot_nso['acf2_id']=''\n",
    "tot_nso['scorecard_filter']='Total'\n",
    "tot_nso['employee_name']='National Office'\n",
    "tot_nso['am_cost_center']=''\n",
    "tot_nso['am_cost_center_name']=''\n",
    "tot_nso['am_cost_center_full_name']=''\n",
    "tot_nso['sm_cost_center']=''\n",
    "tot_nso['sm_cost_center_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(tot_nso)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "tot_nso=tot_nso.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "tot_nso_median=tot_nso.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "tot_nso_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_nso_all3=pd.merge(tot_nso,tot_nso_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "tot_nso_median1=tot_nso.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "tot_nso_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_nso_all4=pd.merge(tot_nso_all3,tot_nso_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "tot_nso_median2=tot_nso.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "tot_nso_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_nso_all5=pd.merge(tot_nso_all4,tot_nso_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "tot_nso_median3=tot_nso.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "tot_nso_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_nso_all6=pd.merge(tot_nso_all5,tot_nso_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "tot_nso_ytdmedian=tot_nso.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "tot_nso_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "tot_nso_all7=pd.merge(tot_nso_all6,tot_nso_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "tot_nso_all7['record_date']=rec_date\n",
    "\n",
    "## keep relevant vars\n",
    "tot_nso_all8=tot_nso_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### APPEND ALL THE DATAFRAME FILTERS (including AMSB) -am total, sm total, national total, \n",
    "df_tot_all=pd.concat([tot_am_all8,tot_sm_all8, tot_nso_all8,sbb_amsb, sbb_am, sbb_sm],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ read in all other dataframes and append #############################\n",
    "## read in gnb\n",
    "df1 = spark.table('anp_cabbtdct1_final.SBB_SC_OUTPUT_GNB')\n",
    "final_gnb0=df1.toPandas()\n",
    "final_gnb=final_gnb0[(final_gnb0.record_date==rec_date)]\n",
    "\n",
    "## read in TDEF\n",
    "df144 = spark.table('anp_cabbtdct1_final.SBB_SC_OUTPUT_TDEF')\n",
    "final_tdef0=df144.toPandas()\n",
    "final_tdef=final_tdef0[(final_tdef0.record_date==rec_date)]\n",
    "\n",
    "## read in Retail Referrals\n",
    "df140 = spark.table('anp_cabbtdct1_final.SBB_SC_OUTPUT_RETAIL_REF')\n",
    "final_retailref0=df140.toPandas()\n",
    "final_retailref=final_retailref0[(final_retailref0.record_date==rec_date)]\n",
    "\n",
    "## read in Branch Adoption\n",
    "df145 = spark.table('anp_cabbtdct1_final.SBB_SC_OUTPUT_BRANCH_ADOPTION')\n",
    "final_branchadopt0=df145.toPandas()\n",
    "final_branchadopt=final_branchadopt0[(final_branchadopt0.record_date==rec_date)]\n",
    "\n",
    "## concatenate\n",
    "df_full=pd.concat([df_tot_all,final_gnb,final_tdef,final_retailref,final_branchadopt],axis=0)\n",
    "#removed final GNB dataframe\n",
    "#df_full=pd.concat([df_tot_all,final_tdef,final_retailref,final_branchadopt],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full.metric_name.unique()\n",
    "#final_retailref[(final_retailref.metric_name==\"AMSB Retail Referrals\")&(final_retailref.level==\"National Office\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create bbs for now; delete later\n",
    "\n",
    "if any(element in gnb_tup for element in df_full.metric_name):\n",
    "    test1=pd.DataFrame({'metric_name':['']})\n",
    "else:\n",
    "    test1 = pd.DataFrame({'metric_name':gnb_tup})\n",
    "\n",
    "### create LEI metric anyway  (in case due to no data in Nov; will delete later if data exists)\n",
    "if any(element in lei_tup for element in df_full.metric_name):\n",
    "    test2=pd.DataFrame({'metric_name':['']})\n",
    "else:\n",
    "    test2 = pd.DataFrame({'metric_name':lei_tup}) \n",
    "\n",
    "if any(element in ctp_tup for element in df_full.metric_name):\n",
    "    test3=pd.DataFrame({'metric_name':['']}) \n",
    "else:\n",
    "    test3 = pd.DataFrame({'metric_name':ctp_tup})\n",
    "\n",
    "if any(element in tdef_tup for element in df_full.metric_name):\n",
    "    test4=pd.DataFrame({'metric_name':['']})\n",
    "else:\n",
    "    test4 = pd.DataFrame({'metric_name':tdef_tup}) \n",
    "\n",
    "if any(element in 'Referrals to BBS' for element in df_full.metric_name):\n",
    "    test00=pd.DataFrame({'metric_name':['']})\n",
    "else:\n",
    "    test00 = pd.DataFrame({'metric_name':['Referrals to BBS']}) \n",
    "\n",
    "## concatenate\n",
    "df_test=pd.concat([test1,test2,test3,test4,test00],axis=0)\n",
    "df_test['temp']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## CREATE GNB, LEI METRICS FOR START OF FISCAL (DUE TO NO DATA) #######################################\n",
    "\n",
    "lev_list=('AMSB','AM','SM','National Office')\n",
    "sc_list=('SBB','Retail','Total')\n",
    "\n",
    "## create dfs\n",
    "df_test3 = pd.DataFrame({'level':lev_list})\n",
    "df_test3['temp']=1\n",
    "\n",
    "df_test4 = pd.DataFrame({'scorecard_filter':sc_list})\n",
    "df_test4['temp']=1\n",
    "\n",
    "result = pd.merge(pd.merge(df_test,df_test3,on=['temp']),df_test4,on=['temp'])\n",
    "result = result.drop('temp', axis=1)\n",
    "\n",
    "## for National Office, drop 'SBB' and 'Retail' scorecard filters; (df contains 'metric_name','level','scorecard_filter')\n",
    "result1=result.loc[((result.level!='National Office') | (result.scorecard_filter!='SBB')) &\n",
    "                   ((result.level!='National Office') | (result.scorecard_filter!='Retail'))]\n",
    "\n",
    "## for AMSB, drop 'Retail' and 'Total' scorecard filters\n",
    "result2=result1.loc[((result1.level!='AMSB') | (result1.scorecard_filter!='Total')) &\n",
    "                   ((result1.level!='AMSB') | (result1.scorecard_filter!='Retail'))]\n",
    "\n",
    "##remove blank metric_name\n",
    "result2=result2[(result2.metric_name!='')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### get all AMSBs\n",
    "df=spark.sql(\"select acf2_id,employee_name,am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by acf2_id order by record_date desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "sbb_hr1=df.toPandas()\n",
    "\n",
    "sbb_hr2=sbb_hr1.copy()\n",
    "sbb_hr2['level']='AMSB'\n",
    "sbb_hr3=sbb_hr2[['acf2_id','employee_name','level','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "result8=result2[(result2.level=='AMSB')]\n",
    "\n",
    "## merge HR data with all metric names\n",
    "result_amsb18 = pd.merge(sbb_hr3,result8,on=['level'],how='left')\n",
    "\n",
    "## order vars\n",
    "result_amsb288=result_amsb18[['metric_name','level','scorecard_filter','acf2_id','employee_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "######################## get all AMs\n",
    "sbb_hr8=sbb_hr1.copy()\n",
    "sbb_hr8['level']='AM'\n",
    "sbb_hr9=sbb_hr8[['level','am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']].drop_duplicates()\n",
    "\n",
    "result10=result2[(result2.level=='AM')]\n",
    "\n",
    "## merge HR data with all metric names\n",
    "result_am28 = pd.merge(sbb_hr9,result10,on=['level'],how='left')\n",
    "\n",
    "result_am28['acf2_id']=''\n",
    "result_am28['employee_name']=result_am28.am_cost_center_full_name\n",
    "\n",
    "## order vars\n",
    "result_am288=result_am28[['metric_name','level','scorecard_filter','acf2_id','employee_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "\n",
    "########################### get all SMs\n",
    "sbb_hr66=sbb_hr1.copy()\n",
    "sbb_hr66['level']='SM'\n",
    "sbb_hr99=sbb_hr66[['level','sm_cost_center','sm_cost_center_name']].drop_duplicates()\n",
    "\n",
    "result100=result2[(result2.level=='SM')]\n",
    "\n",
    "## merge HR data with all metric names\n",
    "result_sm288 = pd.merge(sbb_hr99,result100,on=['level'],how='left')\n",
    "\n",
    "result_sm288['acf2_id']=''\n",
    "result_sm288['am_cost_center']=''\n",
    "result_sm288['am_cost_center_name']=''\n",
    "result_sm288['am_cost_center_full_name']=''\n",
    "result_sm288['employee_name']=result_sm288.sm_cost_center_name\n",
    "\n",
    "## order vars\n",
    "result_sm2881=result_sm288[['metric_name','level','scorecard_filter','acf2_id','employee_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "\n",
    "########################### get NATIONAL OFFICE\n",
    "\n",
    "result16=result2[(result2.level=='National Office')]\n",
    "\n",
    "result16['acf2_id']=''\n",
    "result16['am_cost_center']=''\n",
    "result16['am_cost_center_name']=''\n",
    "result16['am_cost_center_full_name']=''\n",
    "result16['sm_cost_center']=''\n",
    "result16['sm_cost_center_name']=''\n",
    "result16['employee_name']='National Office'\n",
    "\n",
    "## order vars\n",
    "result_nso288=result16[['metric_name','level','scorecard_filter','acf2_id','employee_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "\n",
    "########### CONCATENATE amsb, am, sm, national office\n",
    "df_all9=pd.concat([result_amsb288,result_am288,result_sm2881, result_nso288],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all9.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### create the columns\n",
    "\n",
    "cols = ['metric_name','level','scorecard_filter','acf2_id','employee_name','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "        'sm_cost_center','sm_cost_center_name','november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "        'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark']\n",
    "net_a = pd.DataFrame(columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in df_all9]\n",
    "new= pd.concat([net_a[complementary], df_all9], axis=1, join='outer')\n",
    "#new= pd.merge(net_a, df_all9, how='outer')\n",
    "#new= pd.concat([net_a, df_all9], axis=1, join='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##delete the extra filler row\n",
    "#new= new.drop(labels='[\\,]', axis=0)\n",
    "##convert to float\n",
    "new = new.astype({\"november\": float,\"december\": float,\"january\": float, \n",
    "                                    \"february\": float, \"march\": float,\"april\": float,\"may\": float,\"june\": float,\n",
    "                                    \"july\": float,\"august\": float,\"september\": float,\"october\": float,\"q1\": float,\n",
    "                                    \"q1_benchmark\": float,\"q2\": float,\"q2_benchmark\": float,\"q3\": float,\"q3_benchmark\": float,\n",
    "                                    \"q4\": float,\"q4_benchmark\": float,\"ytd\": float,\"ytd_benchmark\": float})\n",
    "\n",
    "new['record_date']=rec_date\n",
    "\n",
    "## order the vars\n",
    "result_amsb3=new[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate the total dataframe with the month-delayed data\n",
    "df_sc_all=pd.concat([df_full, result_amsb3],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ FILL BLANKS WITH 0s\n",
    "df_sc_all[['november','december','january','february','march','april','may','june','july','august','september','october','q1',\n",
    "           'q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark']]=df_sc_all[['november','december','january','february','march','april','may','june','july',\n",
    "                                                                                                                         'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark',\n",
    "                                                                                                                         'q4','q4_benchmark','ytd','ytd_benchmark']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## CREATE ADDITIONAL METRICS ##################################\n",
    "## select the metrics from gnb net that are the same as gross\n",
    "gross_list=('Net SBB Professional Banking','Net Franchise Banking Net Volume')\n",
    "all_month_final2=df_sc_all[df_sc_all['metric_name'].isin(gross_list)]\n",
    "##rename metric_name to gross\n",
    "all_month_final2['metric_name'] = all_month_final2['metric_name'].replace(['Net SBB Professional Banking', 'Net Franchise Banking Net Volume'], \n",
    "                                                                          ['Gross SBB Professional Banking', 'Gross Franchise Banking Gross Volume'])\n",
    "\n",
    "## order vars\n",
    "all_month_final2=all_month_final2[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "### concatenate\n",
    "all_month_final3=pd.concat([df_sc_all,all_month_final2],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_month_final3.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# calculate total metrics ###################################\n",
    "\n",
    "##(1) calculate Gross Professional Banking Gross Volume\n",
    "gross1_list=('Gross SBB Professional Banking','Gross Professional Student LOC')\n",
    "all_month_gross=all_month_final3[all_month_final3['metric_name'].isin(gross1_list)]\n",
    "all_month_gross['metric_name'] = all_month_gross['metric_name'].replace(['Gross SBB Professional Banking','Gross Professional Student LOC'], \n",
    "                                                                          'Gross Professional Banking Gross Volume')\n",
    "\n",
    "##(2) calculate Total Gross Professional and Franchise Banking\n",
    "tot_gross_list=('Gross SBB Professional Banking','Gross Professional Student LOC','Gross Franchise Banking Gross Volume')\n",
    "all_month_gross1=all_month_final3[all_month_final3['metric_name'].isin(tot_gross_list)]\n",
    "all_month_gross1['metric_name'] = all_month_gross1['metric_name'].replace(['Gross SBB Professional Banking','Gross Professional Student LOC','Gross Franchise Banking Gross Volume'], \n",
    "                                                                          'Total Gross Professional and Franchise Banking')\n",
    "\n",
    "##(3) calculate Total Business Banking Referral Volume\n",
    "tot_ref_list=('ALL Total Commercial Volume','Total MUR Mortgage Volume', 'TDEF Volume')\n",
    "all_month_gross2=all_month_final3[all_month_final3['metric_name'].isin(tot_ref_list)]\n",
    "all_month_gross2['metric_name'] = all_month_gross2['metric_name'].replace(['ALL Total Commercial Volume','Total MUR Mortgage Volume','TDEF Volume'], \n",
    "                                                                          'Total Business Banking Referral Volume')\n",
    "\n",
    "## concatenate these dataframes\n",
    "all_month_final30=pd.concat([all_month_gross2,all_month_gross1,all_month_gross],axis=0)\n",
    "\n",
    "## order vars\n",
    "all_month_final31=all_month_final30[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# CALCULATE ONETD WIDGETS (SUM OF RETAIL REFERRALS, WEALTH REFERRALS, TD SECURITIES)\n",
    "################# CALCULATE BUSINESS ESSENTIALS (SUM OF BCP, CREDIT CARDS, MERCHANT SOLUTIONS, CMS, REFERRALS TO BBS)\n",
    "################# CALCULATE  the other total metrics\n",
    "\n",
    "######### get AMSB first\n",
    "\n",
    "df_sc_all0=df_sc_all[(df_sc_all.level=='AMSB')]\n",
    "df_sc_all1=df_sc_all0[df_sc_all0.metric_name.isin(total_onetd)]\n",
    "df_sc_all1=df_sc_all1.assign(metric_name='Total OneTD Widgets')\n",
    "\n",
    "## Business Essentials\n",
    "df_be_all0=df_sc_all[(df_sc_all.level=='AMSB')]\n",
    "df_be_all1=df_be_all0[df_be_all0.metric_name.isin(total_be)]\n",
    "df_be_all1=df_be_all1.assign(metric_name='Total Business Essentials Widgets')\n",
    "\n",
    "### order the variables and concatenate with other total metrics\n",
    "df_be_all31=df_be_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "df_sc_all31=df_sc_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## get only the AMSBs from the other total metrics\n",
    "all_month_final32=all_month_final31[(all_month_final31.level=='AMSB')]\n",
    "\n",
    "## concatenate all dataframes\n",
    "all_metrics_all=pd.concat([all_month_final32,df_be_all31,df_sc_all31],axis=0)\n",
    "\n",
    "\n",
    "##group by\n",
    "df_sc_all3=all_metrics_all.groupby(by=['level','scorecard_filter','metric_name','acf2_id','employee_name',\n",
    "                 'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                        'november': 'sum',\n",
    "                        'december': 'sum',\n",
    "                        'january': 'sum',\n",
    "                        'february': 'sum',\n",
    "                        'march': 'sum',\n",
    "                        'april': 'sum',\n",
    "                        'may': 'sum',\n",
    "                        'june': 'sum',\n",
    "                        'july': 'sum',\n",
    "                        'august': 'sum',\n",
    "                        'september': 'sum',\n",
    "                        'october': 'sum'})\n",
    "    \n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(df_sc_all3)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "df_sc_all3=df_sc_all3.replace(0.0, np.nan)\n",
    "\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_sc_median=df_sc_all3.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_sc_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sc_all4=pd.merge(df_sc_all3,psa_sc_median,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_sc_median1=df_sc_all3.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_sc_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sc_all4=pd.merge(psa_sc_all4,psa_sc_median1,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_sc_median2=df_sc_all3.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_sc_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sc_all5=pd.merge(psa_sc_all4,psa_sc_median2,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_sc_median3=df_sc_all3.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_sc_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sc_all6=pd.merge(psa_sc_all5,psa_sc_median3,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_sc_ytdmedian=df_sc_all3.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_sc_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sc_all7=pd.merge(psa_sc_all6,psa_sc_ytdmedian,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_sc_all8=psa_sc_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "\n",
    "############### group by AM\n",
    "## OneTD\n",
    "df_am_all0=df_sc_all[(df_sc_all.level=='AM')]\n",
    "df_am_all1=df_am_all0[df_am_all0.metric_name.isin(total_onetd)]\n",
    "df_am_all1=df_am_all1.assign(metric_name='Total OneTD Widgets')\n",
    "\n",
    "## BE\n",
    "df_am1_all0=df_sc_all[(df_sc_all.level=='AM')]\n",
    "df_am1_all1=df_am1_all0[df_am1_all0.metric_name.isin(total_be)]\n",
    "df_am1_all1=df_am1_all1.assign(metric_name='Total Business Essentials Widgets')\n",
    "\n",
    "### order the variables and concatenate with other total metrics\n",
    "df_be_all310=df_am_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "df_sc_all310=df_am1_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## get only the AMSBs from the other total metrics\n",
    "all_month_final320=all_month_final31[(all_month_final31.level=='AM')]\n",
    "\n",
    "## concatenate all dataframes\n",
    "all_metrics_all40=pd.concat([all_month_final320,df_be_all310,df_sc_all310],axis=0)\n",
    "\n",
    "\n",
    "##groupby\n",
    "df_am_all3=all_metrics_all40.groupby(by=['level','scorecard_filter','metric_name','acf2_id',\n",
    "                 'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                        'november': 'sum',\n",
    "                        'december': 'sum',\n",
    "                        'january': 'sum',\n",
    "                        'february': 'sum',\n",
    "                        'march': 'sum',\n",
    "                        'april': 'sum',\n",
    "                        'may': 'sum',\n",
    "                        'june': 'sum',\n",
    "                        'july': 'sum',\n",
    "                        'august': 'sum',\n",
    "                        'september': 'sum',\n",
    "                        'october': 'sum'})\n",
    "\n",
    "df_am_all3['employee_name']=df_am_all3['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(df_am_all3)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "df_am_all3=df_am_all3.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_am_median=df_am_all3.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all9=pd.merge(df_am_all3,psa_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_am_median1=df_am_all3.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all4=pd.merge(psa_am_all9,psa_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_am_median2=df_am_all3.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all5=pd.merge(psa_am_all4,psa_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_am_median3=df_am_all3.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all6=pd.merge(psa_am_all5,psa_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_am_ytdmedian=df_am_all3.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all7=pd.merge(psa_am_all6,psa_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_am_all8=psa_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "\n",
    "############### group by SM\n",
    "\n",
    "## OneTD\n",
    "df_sm_all0=df_sc_all[(df_sc_all.level=='SM')]\n",
    "df_sm_all1=df_sm_all0[df_sm_all0.metric_name.isin(total_onetd)]\n",
    "df_sm_all1=df_sm_all1.assign(metric_name='Total OneTD Widgets')\n",
    "\n",
    "## BE\n",
    "df_sm1_all0=df_sc_all[(df_sc_all.level=='SM')]\n",
    "df_sm1_all1=df_sm1_all0[df_sm1_all0.metric_name.isin(total_be)]\n",
    "df_sm1_all1=df_sm1_all1.assign(metric_name='Total Business Essentials Widgets')\n",
    "\n",
    "### order the variables and concatenate with other total metrics\n",
    "df_be_all314=df_sm_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "df_sc_all314=df_sm1_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## get only the AMSBs from the other total metrics\n",
    "all_month_final324=all_month_final31[(all_month_final31.level=='SM')]\n",
    "\n",
    "## concatenate all dataframes\n",
    "all_metrics_all45=pd.concat([all_month_final324,df_be_all314,df_sc_all314],axis=0)\n",
    "\n",
    "## groupby\n",
    "df_sm_all3=all_metrics_all45.groupby(by=['level','scorecard_filter','metric_name','acf2_id',\n",
    "                 'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                        'november': 'sum',\n",
    "                        'december': 'sum',\n",
    "                        'january': 'sum',\n",
    "                        'february': 'sum',\n",
    "                        'march': 'sum',\n",
    "                        'april': 'sum',\n",
    "                        'may': 'sum',\n",
    "                        'june': 'sum',\n",
    "                        'july': 'sum',\n",
    "                        'august': 'sum',\n",
    "                        'september': 'sum',\n",
    "                        'october': 'sum'})\n",
    "\n",
    "df_sm_all3['employee_name']=df_sm_all3.sm_cost_center_name\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(df_sm_all3)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "df_sm_all3=df_sm_all3.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_sm_median=df_sm_all3.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all9=pd.merge(df_sm_all3,psa_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_sm_median1=df_sm_all3.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all4=pd.merge(psa_sm_all9,psa_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_sm_median2=df_sm_all3.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all5=pd.merge(psa_sm_all4,psa_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_sm_median3=df_sm_all3.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all6=pd.merge(psa_sm_all5,psa_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_sm_ytdmedian=df_sm_all3.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all7=pd.merge(psa_sm_all6,psa_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_sm_all8=psa_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "\n",
    "######## group by National Office\n",
    "\n",
    "## OneTD\n",
    "df_nso_all0=df_sc_all[(df_sc_all.level=='National Office')]\n",
    "df_nso_all1=df_nso_all0[df_nso_all0.metric_name.isin(total_onetd)]\n",
    "df_nso_all1=df_nso_all1.assign(metric_name='Total OneTD Widgets')\n",
    "\n",
    "##BE\n",
    "df_nso1_all0=df_sc_all[(df_sc_all.level=='National Office')]\n",
    "df_nso1_all1=df_nso1_all0[df_nso1_all0.metric_name.isin(total_be)]\n",
    "df_nso1_all1=df_nso1_all1.assign(metric_name='Total Business Essentials Widgets')\n",
    "\n",
    "\n",
    "### order the variables and concatenate with other total metrics\n",
    "df_be_all317=df_nso1_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "df_sc_all317=df_nso_all1[['metric_name','level','acf2_id','employee_name', \n",
    "                            'november','december','january','february','march','april','may','june','july',\n",
    "                            'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "                            'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "                            'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                            'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## get only the AMSBs from the other total metrics\n",
    "all_month_final327=all_month_final31[(all_month_final31.level=='National Office')]\n",
    "\n",
    "## concatenate all dataframes\n",
    "all_metrics_all47=pd.concat([all_month_final327,df_be_all317,df_sc_all317],axis=0)\n",
    "\n",
    "\n",
    "##groupby\n",
    "df_nso_all3=all_metrics_all47.groupby(by=['level','scorecard_filter','metric_name','acf2_id',\n",
    "                 'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                        'november': 'sum',\n",
    "                        'december': 'sum',\n",
    "                        'january': 'sum',\n",
    "                        'february': 'sum',\n",
    "                        'march': 'sum',\n",
    "                        'april': 'sum',\n",
    "                        'may': 'sum',\n",
    "                        'june': 'sum',\n",
    "                        'july': 'sum',\n",
    "                        'august': 'sum',\n",
    "                        'september': 'sum',\n",
    "                        'october': 'sum'})\n",
    "\n",
    "df_nso_all3['employee_name']='National Office'\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(df_nso_all3)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "df_nso_all3=df_nso_all3.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_nso_median=df_nso_all3.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_nso_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_nso_all9=pd.merge(df_nso_all3,psa_nso_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_nso_median1=df_nso_all3.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_nso_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_nso_all4=pd.merge(psa_nso_all9,psa_nso_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_nso_median2=df_nso_all3.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_nso_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_nso_all5=pd.merge(psa_nso_all4,psa_nso_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_nso_median3=df_nso_all3.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_nso_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_nso_all6=pd.merge(psa_nso_all5,psa_nso_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_nso_ytdmedian=df_nso_all3.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_nso_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_nso_all7=pd.merge(psa_nso_all6,psa_nso_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_nso_all8=psa_nso_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "######### CONCATENATE ALL DATAFRAMES FOR ONETD, BE, and other total metrics\n",
    "df_onetd_be_all=pd.concat([psa_sc_all8, psa_am_all8,psa_sm_all8,psa_nso_all8],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate with rest of data\n",
    "df_sc_all10=pd.concat([all_month_final3,df_onetd_be_all],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if the record_date is unique - should be\n",
    "df_sc_all10.record_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc_all10.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sc_all10[(df_sc_all10.employee_name=='GTA') & (df_sc_all10.metric_name=='AMSB Retail Referrals')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table; this dataframe contains all metrics except for LEI\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(df_sc_all10).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_OUTPUT_ALL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
