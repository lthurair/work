{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retail Referrals program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/sharb24/SBB/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "############################# RETAIL REFERRALS ####################################################\n",
    "\n",
    "## this pulls all referrals on a weekly basis\n",
    "dfret=spark.sql(\"select * from anp_cabbtdct1_final.SBB_SC_RETAIL_REFERRALS\") \n",
    "df_ret=dfret.toPandas()\n",
    "\n",
    "df_ret1=df_ret[(df_ret.record_date>=fy_start) & (df_ret.record_date<=rec_date)]\n",
    "\n",
    "## add a new record_date variable\n",
    "retailref=df_ret1.copy()\n",
    "\n",
    "## add the month\n",
    "retailref['month_dt'] = pd.to_datetime(retailref.closed_dt, format='%Y-%m-%d')\n",
    "retailref['month_dt'] = retailref['month_dt'].dt.month\n",
    "\n",
    "import calendar\n",
    "retailref['month_dt'] = retailref['month_dt'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "print(retailref.month_dt.unique())\n",
    "\n",
    "\n",
    "## add the quarter\n",
    "tuple_q1=('november','december','january')\n",
    "tuple_q2=('february','march','april')\n",
    "tuple_q3=('may','june','july')\n",
    "tuple_q4=('august','september','october')\n",
    "\n",
    "def my_callback(row): \n",
    "    if row['month_dt'] in tuple_q1: \n",
    "        return 'Q1' \n",
    "    elif row['month_dt'] in tuple_q2: \n",
    "        return 'Q2' \n",
    "    elif row['month_dt'] in tuple_q3: \n",
    "        return 'Q3' \n",
    "    elif row['month_dt'] in tuple_q4: \n",
    "        return 'Q4'\n",
    "\n",
    "retailref['quarter']=retailref.apply(my_callback, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## BUSINESS LOGIC: AMSB only gets credit once for one customer per quarter##################\n",
    "\n",
    "#####remove duplicates - AMSB gets credit once for same customer\n",
    "## order the leads by acf2,cust_no,and earliest closed_dt and then get the first record\n",
    "retailref = retailref.sort_values(['orig_acf2','final_id','closed_dt','quarter'], ascending=[True, True,True,True])\n",
    "retail2 = retailref.groupby(['orig_acf2','final_id','quarter'], as_index=False).head(1)\n",
    "\n",
    "## ensure the order of vars and save into a table\n",
    "retail2=retail2[['lead_event_id','cust_id','orig_acf2','job_clasfcn_cd','cc_intrnl_org_prty_id',\n",
    "'origtr_branch_no','origtr_line_of_busnes_ds','asignd_to_branch_no','receive_acf2',\n",
    "'new_receiving_lob','initve_prodct_target_ds','initve_prodct_target_cd',\n",
    "'lifecy_reason_ds','lifecy_reason_cd','creatn_dt','action_dt', 'closed_dt',\n",
    "'lead_source_cd','cust_no','final_id','month_dt','quarter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE THE DATA TO A UNIQUE CUST TABLE\n",
    "#retail2.write.mode(\"overwrite\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_working.tbl_bb4179_final_20210813\")\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(retail2).write.mode(\"overwrite\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_RETAIL_REF_CUST\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### query the unique cust table\n",
    "dfret0=spark.table('anp_cabbtdct1_final.SBB_SC_RETAIL_REF_CUST') \n",
    "retail3=dfret0.toPandas()\n",
    "\n",
    "## filter\n",
    "retail3=retail3[(retail3.record_date>=fy_start)]\n",
    "\n",
    "### get hr/alignment\n",
    "df=spark.sql(\"select am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by am_cost_center order by effective_mon desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "dfhr=df.toPandas()\n",
    "\n",
    "dfhr=dfhr[['am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']].drop_duplicates()\n",
    "\n",
    "retail35=pd.merge(retail3,dfhr,left_on=['cc_intrnl_org_prty_id'],right_on=['am_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## include the metric name and scorecard date\n",
    "retail35['metric_name']='AMSB Retail Referrals'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### count referrals\n",
    "retail34=retail35.groupby(by=['orig_acf2','month_dt','metric_name'],as_index=False).aggregate({\n",
    "                    'final_id': 'count'\n",
    "                     })\n",
    "\n",
    "## transpose the counts\n",
    "retail36=retail34.pivot_table(index=['orig_acf2','metric_name'], \n",
    "                    columns=['month_dt'],\n",
    "                     values='final_id', aggfunc='first', fill_value=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "################## CHANGE EVERY FY #############################\n",
    "\n",
    "complementary = [c for c in net_a if c not in retail36]\n",
    "retail37= pd.concat([net_a[complementary], retail36], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "retail37= retail37.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "retail37=retail37.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "### merge back to get final AMSB vars\n",
    "    ### get hr/alignment\n",
    "df1=spark.sql(\"select acf2_id,employee_name,am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by acf2_id order by record_date desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "dfhr=df1.toPandas()\n",
    "\n",
    "retail38=pd.merge(dfhr,retail37,left_on=['acf2_id'],right_on=['orig_acf2'],\n",
    "                   how=\"inner\")\n",
    "\n",
    "retail38['level']='AMSB'\n",
    "retail38['scorecard_filter']='SBB'\n",
    "retail38['record_date']=rec_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(retail38)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "retail38=retail38.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_amsb_medianq1=retail38.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "df_amsb_medianq2=retail38.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "df_amsb_medianq3=retail38.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "df_amsb_medianq4=retail38.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "df_amsb_medianytd=retail38.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_amsb_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_amsb_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_amsb_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_amsb_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_amsb_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "ret_pt11=pd.merge(pd.merge(retail38,df_amsb_medianq1,\n",
    "                on=['metric_name','sm_cost_center'],\n",
    "                how='left'),df_amsb_medianq2,on=['metric_name','sm_cost_center'],how='left')\n",
    "\n",
    "ret_pt22=pd.merge(pd.merge(ret_pt11,df_amsb_medianq3,\n",
    "                on=['metric_name','sm_cost_center'],\n",
    "                how='left'),df_amsb_medianq4,on=['metric_name','sm_cost_center'],how='left')\n",
    "\n",
    "ret_pt338=pd.merge(ret_pt22,df_amsb_medianytd,on=['metric_name','sm_cost_center'],how=\"left\")\n",
    "\n",
    "\n",
    "### get AMSBs\n",
    "amsbret=ret_pt338[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "        'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#################################### ROLL UP TO AM (SBB FILTER) ################################################\n",
    "\n",
    "##group AMSB results\n",
    "amret2=amgrpfunc(amsbret)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(amret2)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "amret2=amret2.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_am_medianq1=amret2.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_am_medianq2=amret2.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_am_medianq3=amret2.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_am_medianq4=amret2.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_am_medianytd=amret2.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_am_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_am_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_am_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_am_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_am_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "ret1=pd.merge(pd.merge(amret2,df_am_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "ret2=pd.merge(pd.merge(ret1,df_am_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "ret3=pd.merge(ret2,df_am_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "ret3['level']='AM'\n",
    "ret3['scorecard_filter']='SBB'\n",
    "ret3['employee_name']=ret3.am_cost_center_full_name\n",
    "ret3['acf2_id']=''\n",
    "\n",
    "### get AM\n",
    "retail_am=ret3[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "        'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center',\n",
    "            'sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## create a copy for Total AM\n",
    "retail_am1=retail_am.copy()\n",
    "retail_am1['scorecard_filter']='Total'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#################################### ROLL UP TO SM ################################################\n",
    "\n",
    "sm_ret=smgrpfunc(retail_am)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(sm_ret)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "sm_ret=sm_ret.replace(0.0, np.nan)\n",
    "\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_sm_medianq1=sm_ret.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_sm_medianq2=sm_ret.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_sm_medianq3=sm_ret.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_sm_medianq4=sm_ret.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_sm_medianytd=sm_ret.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_sm_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_sm_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_sm_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_sm_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_sm_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "sm_ret1=pd.merge(pd.merge(sm_ret,df_sm_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "sm_ret2=pd.merge(pd.merge(sm_ret1,df_sm_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "sm_ret3=pd.merge(sm_ret2,df_sm_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "sm_ret3['acf2_id']=''\n",
    "sm_ret3['level']='SM'\n",
    "sm_ret3['scorecard_filter']='SBB'\n",
    "sm_ret3['employee_name']=sm_ret3.sm_cost_center_name\n",
    "sm_ret3['am_cost_center']=''\n",
    "sm_ret3['am_cost_center_name']=''\n",
    "sm_ret3['am_cost_center_full_name']=''\n",
    "\n",
    "sm_retail=sm_ret3[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "        'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center',\n",
    "            'sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "## make a copy for Total\n",
    "sm_retail1=sm_retail.copy()\n",
    "sm_retail1['scorecard_filter']='Total'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### ROLL UP TO NATIONAL OFFICE ##################################\n",
    "\n",
    "nso_ret=natgrpfunc(sm_retail)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(nso_ret)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "nso_ret=nso_ret.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_nso_medianq1=nso_ret.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_nso_medianq2=nso_ret.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_nso_medianq3=nso_ret.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_nso_medianq4=nso_ret.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_nso_medianytd=nso_ret.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_nso_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_nso_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_nso_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_nso_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_nso_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "nso_ret1=pd.merge(pd.merge(nso_ret,df_nso_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "nso_ret2=pd.merge(pd.merge(nso_ret1,df_nso_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "nso_ret3=pd.merge(nso_ret2,df_nso_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "nso_ret3['acf2_id']=''\n",
    "nso_ret3['level']='National Office'\n",
    "nso_ret3['scorecard_filter']='Total'\n",
    "nso_ret3['employee_name']='National Office'\n",
    "nso_ret3['am_cost_center']=''\n",
    "nso_ret3['am_cost_center_name']=''\n",
    "nso_ret3['am_cost_center_full_name']=''\n",
    "nso_ret3['sm_cost_center']=''\n",
    "nso_ret3['sm_cost_center_name']=''\n",
    "\n",
    "nso_ret3['record_date']=rec_date\n",
    "\n",
    "nso_retail=nso_ret3[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center',\n",
    "            'sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## CONCATENATE ALL DATAFRAMES ########################################\n",
    "## amsb,am sbb, am total, sm sbb, sm total\n",
    "retail_ref_all=pd.concat([amsbret,retail_am,retail_am1,sm_retail,sm_retail1,nso_retail],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in with zeroes\n",
    "retail_ref_allf=retail_ref_all.replace(np.nan,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_ref_allf.record_date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(retail_ref_allf).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_OUTPUT_RETAIL_REF\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF PROGRAM\n",
    "nso_retail[(nso_retail.metric_name==\"AMSB Retail Referrals\")]#&(nso_retail.employee_name==\"GTA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
