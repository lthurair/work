{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GNB.py - process GNB Widgets, Points, Net Auth Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/thural2/THURAL2/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# START GNB PROCESSING ###########################################\n",
    "\n",
    "df12=spark.sql(\"select * from anp_cabbtdct1_working.SBB_GNB\")\n",
    "gnb=df12.toPandas()\n",
    "\n",
    "## make all columns lowercase \n",
    "gnb.columns=gnb.columns.str.lower()\n",
    "\n",
    "## get only this year's data\n",
    "## LATEST DATA\n",
    "gnb_widgets1_filter=gnb[(gnb.inthis>=m1)]\n",
    "\n",
    "from datetime import datetime\n",
    "########## get numeric month\n",
    "gnb_widgets1_filter['month_dt'] = pd.to_datetime(gnb_widgets1_filter.inthis, format='%Y%m')\n",
    "#gnb_widgets1_filter['month_dt'] = gnb_widgets1_filter['month_dt'].dt.month\n",
    "gnb_widgets1_filter['month_dt'] = gnb_widgets1_filter['month_dt'].dt.strftime(\"%B\").str.lower()\n",
    "\n",
    "#import calendar\n",
    "#gnb_widgets1_filter['month_dt'] = gnb_widgets1_filter['month_dt'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "#print(gnb_widgets1_filter.month_dt.unique())\n",
    "\n",
    "##rename logon_id\n",
    "gnb_widgets1_filter.rename(columns = {\"logon_id\":'acf2_id'}, inplace = True) \n",
    " \n",
    "## create record_date\n",
    "gnb_widgets1_filter['record_date']=rec_date\n",
    "\n",
    "## get relevant variables\n",
    "gnb_wid00=gnb_widgets1_filter[['acf2_id','slsbran','prodcd','salebal','franchise_cust',\n",
    "                              'professional_cust','month_dt','gnb','auth_credit','gnb_volume',\n",
    "                              'gnb_points','job_code','am_cost_center','region_id','record_date']]\n",
    "    \n",
    "## convert to float\n",
    "gnb_wid00 = gnb_wid00.astype({'gnb_volume': float})\n",
    "gnb_wid00 = gnb_wid00.astype({'gnb_points': float})\n",
    "gnb_wid00 = gnb_wid00.astype({'auth_credit': float})\n",
    "\n",
    "gnb_wid1=gnb_wid00[(gnb_wid00.job_code=='251801')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_wid00.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_wid00.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "###################################### GNB WIDGETS (SBB FILTER) ##############################################\n",
    "\n",
    "gnb_widgets2_filter=gnb_wid1[(gnb_wid1.gnb=='Y') & (gnb_wid1.gnb_volume>0)]\n",
    "\n",
    "## create a variable to identify the metric\n",
    "gnb_widgets3_filter=gnb_widgets2_filter.assign(metric_name='Total GNB Widgets (Actual)')\n",
    "gnb_wid_df9=gnb_widgets3_filter[['metric_name','acf2_id','slsbran','prodcd','salebal','franchise_cust',\n",
    "                              'professional_cust','month_dt','gnb','auth_credit','gnb_volume',\n",
    "                              'gnb_points','job_code','am_cost_center','region_id','record_date']]\n",
    "\n",
    "## group by logon_id, metric_name, month_dt\n",
    "gnb_wid_df1=gnb_wid_df9.groupby(['acf2_id','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "                'gnb':'count'  # count widgets\n",
    "                })\n",
    "\n",
    "##transpose data\n",
    "gnb_wid_df2 = gnb_wid_df1.pivot_table(index=['acf2_id','metric_name','record_date'], columns=['month_dt'],\n",
    "                     values='gnb', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in gnb_wid_df2]\n",
    "gnb_wid_df3= pd.concat([net_a[complementary], gnb_wid_df2], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df3= gnb_wid_df3.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"november\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"december\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"january\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"february\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"march\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"april\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"may\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"june\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"july\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"august\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"september\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_wid_df3=gnb_wid_df3[['metric_name','acf2_id','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "###################################### GNB POINTS (SBB FILTER) ##############################################\n",
    "\n",
    "df_gnb=gnb_wid1[(gnb_wid1.gnb_points>0)]\n",
    "\n",
    "##filter out the exclusion codes (including Professional Student LOC and Health LOC)\n",
    "df_gnb=df_gnb[~df_gnb['prodcd'].isin(professional_tuple)]\n",
    "\n",
    "###group all data by points and month\n",
    "df_gnb['metric_name'] = df_gnb['gnb_points']\n",
    "gnb_imp0= df_gnb.astype({\"metric_name\": float})\n",
    "gnb_imp0= gnb_imp0.astype({\"metric_name\": str})\n",
    "\n",
    "gnb_imp0[\"metric_name\"].replace({\"1.0\": \"GNB Points 1PT\", \"4.0\": \"GNB Points 4PTS\",\"10.0\": \"GNB Points 10PTS\",\"12.0\": \"GNB Points 12PTS\"}, inplace=True)\n",
    "\n",
    "gnb_imp1=gnb_imp0.groupby(['acf2_id','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "    'gnb_points':\"sum\"  # Sum points\n",
    "    })\n",
    "\n",
    "##transpose data\n",
    "res = gnb_imp1.pivot_table(index=['acf2_id','metric_name','record_date'], columns=['month_dt'],\n",
    "                          values='gnb_points', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "############################# create the total gnb points header ############################\n",
    "\n",
    "result= gnb_imp0.groupby(by=['acf2_id','month_dt','record_date'],as_index=False).aggregate({\n",
    "    'gnb_points':\"sum\"  # Sum auth_credit volume\n",
    "    })\n",
    "\n",
    "result.rename(columns = {\"gnb_points\":'SBB TOTAL POINTS'}, inplace = True) \n",
    "result['metric_name']='Total GNB Points'\n",
    "\n",
    "\n",
    "##transpose the data\n",
    "res1 = result.pivot_table(index=['acf2_id','metric_name','record_date'], columns=['month_dt'],\n",
    "                          values='SBB TOTAL POINTS', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##merge to res\n",
    "gnb_new1=pd.concat([res,res1],axis=0, ignore_index=True)\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "\n",
    "complementary = [c for c in net_a if c not in gnb_new1]\n",
    "gnb_wid_df5= pd.concat([net_a[complementary], gnb_new1], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df5= gnb_wid_df5.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"november\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"december\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"january\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"february\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"march\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"april\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"may\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"june\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"july\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"august\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"september\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_wid_df6=gnb_wid_df5[['metric_name','acf2_id','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_wid_df6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "############################ GNB NET AUTHORIZED VOLUME (SBB FILTER) #########################################\n",
    "\n",
    "##TOTAL SBB NET AUTHORIZED VOLUME (SUM OF LON AND LOC)\n",
    "total_net_auth_filter=gnb_wid1[gnb_wid1.prodcd.isin(gross_all_tuple)]\n",
    "## create a variable to identify the metric\n",
    "total_net_auth_filter=total_net_auth_filter.assign(metric_name='Total SBB Net Authorized Volume')\n",
    "total_net_auth_filter=gnbfilterfunc(total_net_auth_filter)\n",
    "\n",
    "\n",
    "#######LON\n",
    "lon_filter=gnb_wid1[gnb_wid1.prodcd.isin(gross_lon_tuple)]\n",
    "## create a variable to identify the metric\n",
    "lon_filter=lon_filter.assign(metric_name='SBB Net Authorized LON Volume')\n",
    "lon_filter=gnbfilterfunc(lon_filter)\n",
    "\n",
    "\n",
    "#######LOC\n",
    "loc_filter=gnb_wid1[gnb_wid1.prodcd.isin(gross_loc_tuple)]\n",
    "## create a variable to identify the metric\n",
    "loc_filter=loc_filter.assign(metric_name='SBB Net Authorized LOC Volume')\n",
    "loc_filter=gnbfilterfunc(loc_filter)\n",
    "\n",
    "\n",
    "#######SBB PROFESSIONAL BANKING\n",
    "sbb_prof_filter0 = gnb_wid1[(gnb_wid1['professional_cust']=='Y')]\n",
    "sbb_prof_filter=sbb_prof_filter0[~sbb_prof_filter0['prodcd'].isin(gross_student_loc_tuple)]\n",
    "## create a variable to identify the metric\n",
    "sbb_prof_filter=sbb_prof_filter.assign(metric_name='Net SBB Professional Banking')\n",
    "sbb_prof_filter=gnbfilterfunc(sbb_prof_filter)\n",
    "\n",
    "#######PROFESSIONAL STUDENT LOC\n",
    "prof_sloc_filter=gnb_wid1[gnb_wid1.prodcd.isin(gross_student_loc_tuple)]\n",
    "## create a variable to identify the metric\n",
    "prof_sloc_filter=prof_sloc_filter.assign(metric_name='Net Professional Student LOC')\n",
    "prof_sloc_filter=gnbfilterfunc(prof_sloc_filter)\n",
    "\n",
    "#######FRANCHISE\n",
    "franchise_filter = gnb_wid1[(gnb_wid1['franchise_cust']=='Y')]\n",
    "## create a variable to identify the metric\n",
    "franchise_filter=franchise_filter.assign(metric_name='Net Franchise Banking Net Volume')\n",
    "franchise_filter=gnbfilterfunc(franchise_filter)\n",
    "\n",
    "\n",
    "#######TOTAL PROFESSIONAL BANKING NET VOLUME (SUM OF SBB PROF BANKING, PROF STUDENT LOC, HEALTH)\n",
    "total_prof_filter=pd.concat([sbb_prof_filter,prof_sloc_filter],axis=0)\n",
    "total_prof_filter=total_prof_filter.drop(columns='metric_name')\n",
    "## create a variable to identify the metric\n",
    "total_prof_filter=total_prof_filter.assign(metric_name='Net Professional Banking Net Volume')\n",
    "total_prof_filter=gnbfilterfunc(total_prof_filter)\n",
    "\n",
    "\n",
    "########PROFESSIONAL AND FRANCHISE SUM\n",
    "prof_and_franchise_filter=pd.concat([total_prof_filter,franchise_filter],axis=0)\n",
    "prof_and_franchise_filter=prof_and_franchise_filter.drop(columns='metric_name')\n",
    "## create a variable to identify the metric\n",
    "prof_and_franchise_filter=prof_and_franchise_filter.assign(metric_name='Net Professional and Franchise Banking')\n",
    "prof_and_franchise_filter=gnbfilterfunc(prof_and_franchise_filter)\n",
    "\n",
    "\n",
    "## append all of the filters\n",
    "new_df=pd.concat([total_net_auth_filter,lon_filter,loc_filter,sbb_prof_filter,prof_sloc_filter,\n",
    "                  franchise_filter,total_prof_filter,prof_and_franchise_filter],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AGGREGATE DATA #######################\n",
    "\n",
    "###group all data by LOGON_ID,MONTH,AND METRIC\n",
    "    ## rollup to LOGON_ID\n",
    "new_df1=new_df.groupby(['acf2_id','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "    'auth_credit':\"sum\"  # Sum auth_credit volume\n",
    "    })\n",
    "\n",
    "##transpose data\n",
    "new_df2 = new_df1.pivot_table(index=['acf2_id','metric_name','record_date'], columns=['month_dt'],\n",
    "                     values='auth_credit', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in new_df2]\n",
    "gnb_wid_df7= pd.concat([net_a[complementary], new_df2], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df7= gnb_wid_df7.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"november\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"december\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"january\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"february\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"march\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"april\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"may\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"june\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"july\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"august\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"september\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_wid_df8=gnb_wid_df7[['metric_name','acf2_id','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### APPEND THE DATAFRAMES FOR WIDGETS,POINTS,VOLUME############################\n",
    "gnb_all=pd.concat([gnb_wid_df3,gnb_wid_df6,gnb_wid_df8],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### PROCESS FOR AMSB #############################################\n",
    "newvarfunc(gnb_all)\n",
    "\n",
    "############## merge to hr/alignment to get am/sm cc\n",
    "df=spark.sql(\"select acf2_id,employee_name,am_cost_center,am_cost_center_name,am_cost_center_full_name, \\\n",
    "                     sm_cost_center,sm_cost_center_name from \\\n",
    "                     (select *, row_number() over(partition by acf2_id order by record_date desc) as ran \\\n",
    "                     from anp_cabbtdct1_final.HRM_SBB_ALIGNMENT0)b where ran=1\")\n",
    "dfhr=df.toPandas()\n",
    "\n",
    "dfhr=dfhr[['acf2_id','employee_name','am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']]\n",
    "\n",
    "## merge \n",
    "gnb_all00=pd.merge(gnb_all,dfhr,how='left',left_on=['acf2_id'],right_on=['acf2_id'])\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb_all00=gnb_all00.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_amsb_medianq1=gnb_all00.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "df_amsb_medianq2=gnb_all00.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "df_amsb_medianq3=gnb_all00.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "df_amsb_medianq4=gnb_all00.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "df_amsb_medianytd=gnb_all00.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_amsb_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_amsb_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_amsb_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_amsb_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_amsb_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt1=pd.merge(pd.merge(gnb_all00,df_amsb_medianq1,\n",
    "                on=['metric_name','sm_cost_center'],\n",
    "                how='left'),df_amsb_medianq2,on=['metric_name','sm_cost_center'],how='left')\n",
    "\n",
    "gnb_pt2=pd.merge(pd.merge(gnb_pt1,df_amsb_medianq3,\n",
    "                on=['metric_name','sm_cost_center'],\n",
    "                how='left'),df_amsb_medianq4,on=['metric_name','sm_cost_center'],how='left')\n",
    "\n",
    "gnb_pt3=pd.merge(gnb_pt2,df_amsb_medianytd,on=['metric_name','sm_cost_center'],how=\"left\")\n",
    "\n",
    "gnb_pt3['level']='AMSB'\n",
    "gnb_pt3['scorecard_filter']='SBB'\n",
    "\n",
    "gnb_amsb=gnb_pt3[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_amsb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# CREATE THE AM SBB OUTPUT ##########################################\n",
    "\n",
    "gnb110=amgrpfunc(gnb_amsb)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb110)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb110=gnb110.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_am_medianq1=gnb110.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_am_medianq2=gnb110.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_am_medianq3=gnb110.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_am_medianq4=gnb110.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_am_medianytd=gnb110.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_am_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_am_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_am_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_am_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_am_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt11=pd.merge(pd.merge(gnb110,df_am_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt22=pd.merge(pd.merge(gnb_pt11,df_am_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt33=pd.merge(gnb_pt22,df_am_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt33['acf2_id']=''\n",
    "gnb_pt33['level']='AM'\n",
    "gnb_pt33['scorecard_filter']='SBB'\n",
    "gnb_pt33['employee_name']=gnb_pt33.am_cost_center_full_name\n",
    "\n",
    "gnb_am_sbb=gnb_pt33[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CREATE THE SM SBB OUTPUT ##########################################\n",
    "\n",
    "gnb111=smgrpfunc(gnb_am_sbb)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb111)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb111=gnb111.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_sm_medianq1=gnb111.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_sm_medianq2=gnb111.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_sm_medianq3=gnb111.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_sm_medianq4=gnb111.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_sm_medianytd=gnb111.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_sm_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_sm_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_sm_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_sm_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_sm_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt111=pd.merge(pd.merge(gnb111,df_sm_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt222=pd.merge(pd.merge(gnb_pt111,df_sm_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt333=pd.merge(gnb_pt222,df_sm_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt333['acf2_id']=''\n",
    "gnb_pt333['level']='SM'\n",
    "gnb_pt333['scorecard_filter']='SBB'\n",
    "gnb_pt333['employee_name']=gnb_pt333.sm_cost_center_name\n",
    "gnb_pt333['am_cost_center']=''\n",
    "gnb_pt333['am_cost_center_name']=''\n",
    "gnb_pt333['am_cost_center_full_name']=''\n",
    "\n",
    "gnb_sm_sbb=gnb_pt333[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "################################# GET RETAIL FILTER ##############################################\n",
    "\n",
    "gnb_wid99=gnb_wid00[(gnb_wid00.job_code!='251801') & (gnb_wid00.job_code !='436201')]\n",
    "\n",
    "gnb_wid99.loc[gnb_wid99['slsbran'] =='3838', \"am_cost_center\"] ='3838'\n",
    "gnb_wid99.loc[gnb_wid99['slsbran'] =='5311', \"am_cost_center\"] ='5311'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "##################################### RETAIL GNB WIDGETS############################################\n",
    "\n",
    "gnb_widgets2_filter=gnb_wid99[(gnb_wid99.gnb=='Y') & (gnb_wid99.gnb_volume>0)]\n",
    "\n",
    "## create a variable to identify the metric\n",
    "gnb_widgets3_filter=gnb_widgets2_filter.assign(metric_name='Total GNB Widgets (Actual)')\n",
    "gnb_wid_df9=gnb_widgets3_filter[['metric_name','acf2_id','slsbran','prodcd','salebal','franchise_cust',\n",
    "                              'professional_cust','month_dt','gnb','auth_credit','gnb_volume',\n",
    "                              'gnb_points','job_code','am_cost_center','region_id','record_date']]\n",
    "\n",
    "## group by logon_id, metric_name, inthis\n",
    "gnb_wid_df1=gnb_wid_df9.groupby(['am_cost_center','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "                'gnb':'count'  # count widgets\n",
    "                })\n",
    "\n",
    "##transpose data\n",
    "gnb_wid_df2 = gnb_wid_df1.pivot_table(index=['am_cost_center','metric_name','record_date'], columns=['month_dt'],\n",
    "                     values='gnb', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "\n",
    "complementary = [c for c in net_a if c not in gnb_wid_df2]\n",
    "gnb_wid_df3= pd.concat([net_a[complementary], gnb_wid_df2], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df3= gnb_wid_df3.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"november\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"december\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"january\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"february\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"march\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"april\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"may\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"june\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"july\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"august\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"september\": float})\n",
    "gnb_wid_df3 = gnb_wid_df3.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_wid_ret=gnb_wid_df3[['metric_name','am_cost_center','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "###################################### RETAIL GNB POINTS #######################################\n",
    "\n",
    "df_gnb22=gnb_wid99[(gnb_wid99.gnb_points>0)]\n",
    "\n",
    "##filter out the exclusion codes (including Professional Student LOC and Health LOC)\n",
    "df_gnb33=df_gnb22[~df_gnb22['prodcd'].isin(professional_tuple)]\n",
    "\n",
    "###group all data by points and month\n",
    "df_gnb33['metric_name'] = df_gnb33['gnb_points']\n",
    "df_gnb55= df_gnb33.astype({\"metric_name\": float})\n",
    "gnb_imp44= df_gnb55.astype({\"metric_name\": str})\n",
    "\n",
    "gnb_imp44[\"metric_name\"].replace({\"1.0\": \"GNB Points 1PT\", \"4.0\": \"GNB Points 4PTS\",\"10.0\": \"GNB Points 10PTS\",\"12.0\": \"GNB Points 12PTS\"}, inplace=True)\n",
    "\n",
    "gnb_imp11=gnb_imp44.groupby(['am_cost_center','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "    'gnb_points':\"sum\"  # Sum points\n",
    "    })\n",
    "\n",
    "##transpose data\n",
    "res = gnb_imp11.pivot_table(index=['am_cost_center','metric_name','record_date'], columns=['month_dt'],\n",
    "                          values='gnb_points', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "############################# create the total gnb points header ############################\n",
    "\n",
    "result= gnb_imp44.groupby(by=['am_cost_center','month_dt','record_date'],as_index=False).aggregate({\n",
    "    'gnb_points':\"sum\"  # Sum auth_credit volume\n",
    "    })\n",
    "\n",
    "result.rename(columns = {\"gnb_points\":'SBB TOTAL POINTS'}, inplace = True) \n",
    "result['metric_name']='Total GNB Points'\n",
    "\n",
    "\n",
    "##transpose the data\n",
    "res1 = result.pivot_table(index=['am_cost_center','metric_name','record_date'], columns=['month_dt'],\n",
    "                          values='SBB TOTAL POINTS', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "##merge to res\n",
    "gnb_new1=pd.concat([res,res1],axis=0, ignore_index=True)\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in gnb_new1]\n",
    "gnb_wid_df5= pd.concat([net_a[complementary], gnb_new1], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df5= gnb_wid_df5.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"november\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"december\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"january\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"february\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"march\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"april\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"may\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"june\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"july\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"august\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"september\": float})\n",
    "gnb_wid_df5 = gnb_wid_df5.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_pt_df6=gnb_wid_df5[['metric_name','am_cost_center','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "############################ GNB RETAIL NET AUTHORIZED VOLUME ##################################\n",
    "\n",
    "##TOTAL SBB NET AUTHORIZED VOLUME (SUM OF LON AND LOC)\n",
    "total_net_auth_filter=gnb_wid99[gnb_wid99.prodcd.isin(gross_all_tuple)]\n",
    "## create a variable to identify the metric\n",
    "total_net_auth_filter=total_net_auth_filter.assign(metric_name='Total SBB Net Authorized Volume')\n",
    "total_net_auth_filter=gnbfilterfunc(total_net_auth_filter)\n",
    "\n",
    "#######LON\n",
    "lon_filter=gnb_wid99[gnb_wid99.prodcd.isin(gross_lon_tuple)]\n",
    "## create a variable to identify the metric\n",
    "lon_filter=lon_filter.assign(metric_name='SBB Net Authorized LON Volume')\n",
    "lon_filter=gnbfilterfunc(lon_filter)\n",
    "\n",
    "#######LOC\n",
    "loc_filter=gnb_wid99[gnb_wid99.prodcd.isin(gross_loc_tuple)]\n",
    "## create a variable to identify the metric\n",
    "loc_filter=loc_filter.assign(metric_name='SBB Net Authorized LOC Volume')\n",
    "loc_filter=gnbfilterfunc(loc_filter)\n",
    "\n",
    "#######SBB PROFESSIONAL BANKING\n",
    "sbb_prof_filter = gnb_wid99[(gnb_wid99['professional_cust']=='Y') &\n",
    "                           ((gnb_wid99.prodcd!='S021') | (gnb_wid99.prodcd!='S026') | (gnb_wid99.prodcd!='L290'))]\n",
    "## create a variable to identify the metric\n",
    "sbb_prof_filter=sbb_prof_filter.assign(metric_name='Net SBB Professional Banking')\n",
    "sbb_prof_filter=gnbfilterfunc(sbb_prof_filter)\n",
    "\n",
    "#######PROFESSIONAL STUDENT LOC\n",
    "prof_sloc_filter=gnb_wid99[gnb_wid99.prodcd.isin(gross_student_loc_tuple)]\n",
    "## create a variable to identify the metric\n",
    "prof_sloc_filter=prof_sloc_filter.assign(metric_name='Net Professional Student LOC')\n",
    "prof_sloc_filter=gnbfilterfunc(prof_sloc_filter)\n",
    "\n",
    "#######FRANCHISE\n",
    "franchise_filter = gnb_wid99[(gnb_wid99['franchise_cust']=='Y')]\n",
    "## create a variable to identify the metric\n",
    "franchise_filter=franchise_filter.assign(metric_name='Net Franchise Banking Net Volume')\n",
    "franchise_filter=gnbfilterfunc(franchise_filter)\n",
    "\n",
    "\n",
    "#######TOTAL PROFESSIONAL BANKING NET VOLUME (SUM OF SBB PROF BANKING, PROF STUDENT LOC, HEALTH)\n",
    "total_prof_filter=pd.concat([sbb_prof_filter,prof_sloc_filter],axis=0)\n",
    "total_prof_filter=total_prof_filter.drop(columns='metric_name')\n",
    "## create a variable to identify the metric\n",
    "total_prof_filter=total_prof_filter.assign(metric_name='Net Professional Banking Net Volume')\n",
    "total_prof_filter=gnbfilterfunc(total_prof_filter)\n",
    "\n",
    "########PROFESSIONAL AND FRANCHISE SUM\n",
    "prof_and_franchise_filter=pd.concat([total_prof_filter,franchise_filter],axis=0)\n",
    "prof_and_franchise_filter=prof_and_franchise_filter.drop(columns='metric_name')\n",
    "## create a variable to identify the metric\n",
    "prof_and_franchise_filter=prof_and_franchise_filter.assign(metric_name='Net Professional and Franchise Banking')\n",
    "prof_and_franchise_filter=gnbfilterfunc(prof_and_franchise_filter)\n",
    "\n",
    "\n",
    "## append all of the filters\n",
    "new_df=pd.concat([total_net_auth_filter,lon_filter,loc_filter,sbb_prof_filter,prof_sloc_filter,\n",
    "                  franchise_filter,total_prof_filter,prof_and_franchise_filter],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AGGREGATE DATA #######################\n",
    "\n",
    "###group all data by LOGON_ID,MONTH,AND METRIC\n",
    "    ## rollup to LOGON_ID\n",
    "new_df1=new_df.groupby(['am_cost_center','month_dt','metric_name','record_date'],as_index=False).aggregate({\n",
    "    'auth_credit':\"sum\"  # Sum auth_credit volume\n",
    "    })\n",
    "\n",
    "##transpose data\n",
    "new_df2 = new_df1.pivot_table(index=['am_cost_center','metric_name','record_date'], columns=['month_dt'],\n",
    "                     values='auth_credit', aggfunc='first', fill_value=0).reset_index()\n",
    "\n",
    "#### get months\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "\n",
    "complementary = [c for c in net_a if c not in new_df2]\n",
    "gnb_wid_df7= pd.concat([net_a[complementary], new_df2], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "gnb_wid_df7= gnb_wid_df7.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"november\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"december\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"january\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"february\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"march\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"april\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"may\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"june\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"july\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"august\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"september\": float})\n",
    "gnb_wid_df7 = gnb_wid_df7.astype({\"october\": float})\n",
    "\n",
    "##order the vars\n",
    "gnb_auth_df8=gnb_wid_df7[['metric_name','am_cost_center','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### APPEND THE DATAFRAMES FOR WIDGETS,POINTS,VOLUME############################\n",
    "\n",
    "gnb_all_retail=pd.concat([gnb_pt_df6,gnb_wid_ret,gnb_auth_df8],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## PROCESS RETAIL AM #######################################################\n",
    "\n",
    "### calculate qtd and ytd\n",
    "newvarfunc(gnb_all_retail)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb_all_retail=gnb_all_retail.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_amsb_medianq1=gnb_all_retail.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_amsb_medianq2=gnb_all_retail.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_amsb_medianq3=gnb_all_retail.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_amsb_medianq4=gnb_all_retail.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_amsb_medianytd=gnb_all_retail.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_amsb_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_amsb_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_amsb_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_amsb_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_amsb_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt1=pd.merge(pd.merge(gnb_all_retail,df_amsb_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_amsb_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt2=pd.merge(pd.merge(gnb_pt1,df_amsb_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_amsb_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt3=pd.merge(gnb_pt2,df_amsb_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "\n",
    "############## merge to hr/alignment to get am/sm cc\n",
    "df = spark.table('anp_cabbtdct1_final.latest_hrm_sbb')\n",
    "dfhr=df.toPandas()\n",
    "\n",
    "dfhr=dfhr[['am_cost_center','am_cost_center_name','am_cost_center_full_name','sm_cost_center','sm_cost_center_name']].drop_duplicates()\n",
    "\n",
    "## merge \n",
    "gnb_all=pd.merge(gnb_pt3,dfhr,how='left',left_on=['am_cost_center'],right_on=['am_cost_center'])\n",
    "\n",
    "gnb_all['level']='AM'\n",
    "gnb_all['scorecard_filter']='Retail'\n",
    "gnb_all['acf2_id']=''\n",
    "gnb_all['employee_name']=gnb_all.am_cost_center_full_name\n",
    "\n",
    "gnb_am_retail_all=gnb_all[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# CREATE THE SM RETAIL OUTPUT ##########################################\n",
    "\n",
    "gnb111=smgrpfunc(gnb_am_retail_all)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb111)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb111=gnb111.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_sm_medianq1=gnb111.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_sm_medianq2=gnb111.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_sm_medianq3=gnb111.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_sm_medianq4=gnb111.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_sm_medianytd=gnb111.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_sm_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_sm_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_sm_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_sm_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_sm_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt111=pd.merge(pd.merge(gnb111,df_sm_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt222=pd.merge(pd.merge(gnb_pt111,df_sm_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt333=pd.merge(gnb_pt222,df_sm_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt333['acf2_id']=''\n",
    "gnb_pt333['level']='SM'\n",
    "gnb_pt333['scorecard_filter']='Retail'\n",
    "gnb_pt333['employee_name']=gnb_pt333.sm_cost_center_name\n",
    "gnb_pt333['am_cost_center']=''\n",
    "gnb_pt333['am_cost_center_name']=''\n",
    "gnb_pt333['am_cost_center_full_name']=''\n",
    "\n",
    "gnb_pt344=gnb_pt333[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# CREATE THE AM TOTAL OUTPUT ##########################################\n",
    "## concatenate sbb and retail filters\n",
    "gnb_am=pd.concat([gnb_am_retail_all,gnb_am_sbb],axis=0)\n",
    "\n",
    "## group by AM\n",
    "gnb110=amgrpfunc(gnb_am)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb110)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb110=gnb110.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_am_medianq1=gnb110.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_am_medianq2=gnb110.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_am_medianq3=gnb110.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_am_medianq4=gnb110.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_am_medianytd=gnb110.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_am_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_am_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_am_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_am_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_am_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt11=pd.merge(pd.merge(gnb110,df_am_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt22=pd.merge(pd.merge(gnb_pt11,df_am_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_am_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt338=pd.merge(gnb_pt22,df_am_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt338['acf2_id']=''\n",
    "gnb_pt338['level']='AM'\n",
    "gnb_pt338['scorecard_filter']='Total'\n",
    "gnb_pt338['employee_name']=gnb_pt338.am_cost_center_full_name\n",
    "\n",
    "gnb_pt348=gnb_pt338[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# CREATE THE SM TOTAL OUTPUT ##########################################\n",
    "\n",
    "## concatenate sbb and retail filters\n",
    "gnb_sm=pd.concat([gnb_pt344,gnb_sm_sbb],axis=0)\n",
    "\n",
    "gnb111=smgrpfunc(gnb_pt348)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb111)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb111=gnb111.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_sm_medianq1=gnb111.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_sm_medianq2=gnb111.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_sm_medianq3=gnb111.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_sm_medianq4=gnb111.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_sm_medianytd=gnb111.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_sm_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_sm_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_sm_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_sm_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_sm_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt111=pd.merge(pd.merge(gnb111,df_sm_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt222=pd.merge(pd.merge(gnb_pt111,df_sm_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_sm_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt30=pd.merge(gnb_pt222,df_sm_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt30['acf2_id']=''\n",
    "gnb_pt30['level']='SM'\n",
    "gnb_pt30['scorecard_filter']='Total'\n",
    "gnb_pt30['employee_name']=gnb_pt30.sm_cost_center_name\n",
    "gnb_pt30['am_cost_center']=''\n",
    "gnb_pt30['am_cost_center_name']=''\n",
    "gnb_pt30['am_cost_center_full_name']=''\n",
    "\n",
    "gnb_pt350=gnb_pt30[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# CREATE THE NATIONAL OFFICE TOTAL #############################\n",
    "\n",
    "gnb115=natgrpfunc(gnb_pt350)\n",
    "\n",
    "##CREATE THE Q1,Q2,Q3,Q3,YTD VARIABLES\n",
    "newvarfunc(gnb115)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "gnb115=gnb115.replace(0.0, np.nan)\n",
    "\n",
    "### calculate qtd and ytd benchmarks\n",
    "##CREATE A BENCHMARK (based on quarter median)\n",
    "df_nso_medianq1=gnb115.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "df_nso_medianq2=gnb115.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "df_nso_medianq3=gnb115.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "df_nso_medianq4=gnb115.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "df_nso_medianytd=gnb115.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "df_nso_medianq1.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "df_nso_medianq2.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "df_nso_medianq3.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "df_nso_medianq4.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "df_nso_medianytd.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "\n",
    "### merge to dataframe\n",
    "gnb_pt116=pd.merge(pd.merge(gnb115,df_nso_medianq1,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq2,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt225=pd.merge(pd.merge(gnb_pt116,df_nso_medianq3,\n",
    "                on=['metric_name'],\n",
    "                how='left'),df_nso_medianq4,on=['metric_name'],how='left')\n",
    "\n",
    "gnb_pt300=pd.merge(gnb_pt225,df_nso_medianytd,on=['metric_name'],how=\"left\")\n",
    "\n",
    "gnb_pt300['acf2_id']=''\n",
    "gnb_pt300['level']='National Office'\n",
    "gnb_pt300['scorecard_filter']='Total'\n",
    "gnb_pt300['employee_name']='National Office'\n",
    "gnb_pt300['am_cost_center']=''\n",
    "gnb_pt300['am_cost_center_name']=''\n",
    "gnb_pt300['am_cost_center_full_name']=''\n",
    "gnb_pt300['sm_cost_center']=''\n",
    "gnb_pt300['sm_cost_center_name']=''\n",
    "\n",
    "gnb_pt300['record_date']=rec_date\n",
    "\n",
    "gnb_ptnso=gnb_pt300[['metric_name','level','acf2_id','employee_name','november','december','january',\n",
    "           'february','march','april','may','june','july','august','september','october',\n",
    "           'q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark','q4','q4_benchmark',\n",
    "           'ytd','ytd_benchmark','am_cost_center','am_cost_center_name',\n",
    "           'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "           'scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### CONCATENATE ALL DATAFRAMES ################################\n",
    "\n",
    "## amsb,ramsb, am sbb, sm sbb, am retail, sm retail, am total, sm total, nso total\n",
    "gnb_allf=pd.concat([gnb_amsb,gnb_sm_sbb,gnb_am_sbb,\n",
    "                  gnb_am_retail_all,gnb_pt344,\n",
    "                  gnb_pt348,gnb_pt350,gnb_ptnso],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_allf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_allf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in with zeroes\n",
    "gnb_allf=gnb_allf.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "gnb_allf[['november','december','january','february','march','april','may','june','july','august',\n",
    "                  'september','october','q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark',\n",
    "                            'q4','q4_benchmark','ytd','ytd_benchmark']]=gnb_allf[['november','december','january','february','march','april','may','june','july','august',\n",
    "                  'september','october','q1','q1_benchmark','q2','q2_benchmark','q3','q3_benchmark',\n",
    "                            'q4','q4_benchmark','ytd','ytd_benchmark']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.types import *\n",
    "#create schema for your dataframe\n",
    "#schema = StructType([StructField(\"metric_name\", StringType(), True)\\\n",
    "#                   ,StructField(\"level\", StringType(), True)\\\n",
    "#                   ,StructField(\"acf2_id\", StringType(), True)\\\n",
    "#                     ,StructField(\"employee_name\", StringType(), True)\\\n",
    "#                     ,StructField(\"november\", FloatType(), True)\\\n",
    "#                     ,StructField(\"december\", FloatType(), True)\\\n",
    "#                     ,StructField(\"january\", FloatType(), True)\\\n",
    "#                     ,StructField(\"february\", FloatType(), True)\\\n",
    "#                     ,StructField(\"march\", FloatType(), True)\\\n",
    "#                     ,StructField(\"april\", FloatType(), True)\\\n",
    "#                     ,StructField(\"may\", FloatType(), True)\\\n",
    "#                     ,StructField(\"june\", FloatType(), True)\\\n",
    "#                     ,StructField(\"july\", FloatType(), True)\\\n",
    "#                     ,StructField(\"august\", FloatType(), True)\\\n",
    "#                     ,StructField(\"september\", FloatType(), True)\\\n",
    "#                     ,StructField(\"october\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q1\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q1_benchmark\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q2\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q2_benchmark\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q3\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q3_benchmark\", FloatType(), True)\\\n",
    "#                    ,StructField(\"q4\", FloatType(), True)\\\n",
    "#                     ,StructField(\"q4_benchmark\", FloatType(), True)\\\n",
    "#                     ,StructField(\"ytd\", FloatType(), True)\\\n",
    "#                     ,StructField(\"ytd_benchmark\", FloatType(), True)\\\n",
    "#                     ,StructField(\"am_cost_center\", StringType(), True)\\\n",
    "#                     ,StructField(\"am_cost_center_name\", StringType(), True)\\\n",
    "#                     ,StructField(\"am_cost_center_full_name\", StringType(), True)\\\n",
    "#                     ,StructField(\"sm_cost_center\", StringType(), True)\\\n",
    "#                      ,StructField(\"sm_cost_center_name\", StringType(), True)\\\n",
    "#                      ,StructField(\"scorecard_filter\", StringType(), True)\\\n",
    "#                      ,StructField(\"record_date\", StringType(), True)])\n",
    "\n",
    "#create spark dataframe using schema\n",
    "#gnb_allfinal = spark.createDataFrame(gnb_allf,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(gnb_allf).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_OUTPUT_GNB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
