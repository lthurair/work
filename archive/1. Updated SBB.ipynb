{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBB.py program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/thural2/THURAL2/updated/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### FIRST PROCESS THE GROSS VOLUME SEGMENTATION METRICS###########################################\n",
    "cred_fil=spark.sql(\"select * from anp_cabbtdct1_final.psa_elig_amsb\")\n",
    "cred_sbb_filter=cred_fil.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "cred_sbb_filter=cred_sbb_filter.astype({\"psa_month\": int})\n",
    "import calendar\n",
    "cred_sbb_filter['psa_month'] = cred_sbb_filter['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "cred_sbb_filter.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### subset for GROSS VOLUME SEGMENTATION METRICS AND REST OF PSA METRICS\n",
    "cred_sbb_filter0=cred_sbb_filter[(cred_sbb_filter.seg_ind==1)]\n",
    "cred_sbb_filter00=filterfunc(cred_sbb_filter0)\n",
    "\n",
    "df_mif_psa=cred_sbb_filter[(cred_sbb_filter.seg_ind==0)]\n",
    "\n",
    "## create metric name for rest of psa metrics\n",
    "\n",
    "############################# GROSS VOLUME ###########################################\n",
    "## SBB TAB: TOTAL SBB GROSS VOLUME\n",
    "sbb_gross_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_all_tuple)]\n",
    "sbb_gross_filter=sbb_gross_filter.assign(metric_name='Total SBB Gross Volume')\n",
    "sbb_gross_filter=filterfunc(sbb_gross_filter)\n",
    "\n",
    "## SBB GROSS LOC VOLUME\n",
    "gross_loc_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_loc_tuple)]\n",
    "gross_loc_filter=gross_loc_filter.assign(metric_name='SBB Gross LOC Volume')\n",
    "gross_loc_filter=filterfunc(gross_loc_filter)\n",
    "\n",
    "## SBB GROSS LON VOLUME\n",
    "gross_lon_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_lon_tuple)]\n",
    "gross_lon_filter=gross_lon_filter.assign(metric_name='SBB Gross LON Volume')\n",
    "gross_lon_filter=filterfunc(gross_lon_filter)\n",
    "\n",
    "## SBB GROSS PROFESSIONAL STUDENT LOC VOLUME\n",
    "gross_prof_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(gross_student_loc_tuple)]\n",
    "gross_prof_filter=gross_prof_filter.assign(metric_name='Gross Professional Student LOC')\n",
    "gross_prof_filter=filterfunc(gross_prof_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "gross_all=pd.concat([sbb_gross_filter,gross_loc_filter,gross_lon_filter,gross_prof_filter],axis=0)\n",
    "\n",
    "########################## CREDIT CARDS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL CREDIT CARDS\n",
    "sbb_cc_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_cc_tuple)]\n",
    "sbb_cc_filter=sbb_cc_filter.assign(metric_name='Total Credit Cards')\n",
    "sbb_cc_filter=filterfunc(sbb_cc_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_bv_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_visa_cc_tuple)]\n",
    "sbb_bv_filter=sbb_bv_filter.assign(metric_name='Credit Cards - Business VISA')\n",
    "sbb_bv_filter=filterfunc(sbb_bv_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_btv_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_travel_tuple)]\n",
    "sbb_btv_filter=sbb_btv_filter.assign(metric_name='Credit Cards - Business Travel VISA')\n",
    "sbb_btv_filter=filterfunc(sbb_btv_filter)\n",
    "\n",
    "## SBB TAB: AEROPLAN BUSINESS\n",
    "sbb_aero_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(business_aero_tuple)]\n",
    "sbb_aero_filter=sbb_aero_filter.assign(metric_name='Credit Cards - Aeroplan Business')\n",
    "sbb_aero_filter=filterfunc(sbb_aero_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT NO FEE\n",
    "sbb_nofee_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(bus_nofee_tuple)]\n",
    "sbb_nofee_filter=sbb_nofee_filter.assign(metric_name='Credit Cards - Business Select No Fee')\n",
    "sbb_nofee_filter=filterfunc(sbb_nofee_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT FEE\n",
    "sbb_fee_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(bus_fee_tuple)]\n",
    "sbb_fee_filter=sbb_fee_filter.assign(metric_name='Credit Cards - Business Select Fee')\n",
    "sbb_fee_filter=filterfunc(sbb_fee_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "cc_all=pd.concat([sbb_cc_filter,sbb_bv_filter,sbb_btv_filter,sbb_aero_filter,\n",
    "                  sbb_nofee_filter,sbb_fee_filter],axis=0)\n",
    "\n",
    "########################## MERCHANT SOLUTIONS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL MERCHANT SOLUTIONS\n",
    "merchant_all=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_mer_tuple)]\n",
    "merchant_all=merchant_all.assign(metric_name='Total Merchant Solutions')\n",
    "merchant_all=filterfunc(merchant_all)\n",
    "\n",
    "################################ CMS ###############################################\n",
    "\n",
    "## SBB TAB: TOTAL CMS\n",
    "cms_all=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_cms_tuple)]\n",
    "cms_all=cms_all.assign(metric_name='Total Cash Management Services (including RDC)')\n",
    "cms_all=filterfunc(cms_all)\n",
    "\n",
    "################################ COMMERCIAL VOLUME ###################################\n",
    "\n",
    "## SBB TAB: TOTAL COMMERCIAL VOLUME\n",
    "sbb_com_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_com_tuple)]\n",
    "sbb_com_filter=sbb_com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "sbb_com_filter=filterfunc(sbb_com_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "sbb_dep_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(com_deposit_tuple)]\n",
    "sbb_dep_filter=sbb_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "sbb_dep_filter=filterfunc(sbb_dep_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL LOAN VOLUME\n",
    "sbb_loan_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(com_loan_tuple)]\n",
    "sbb_loan_filter=sbb_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "sbb_loan_filter=filterfunc(sbb_loan_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all=pd.concat([sbb_com_filter,sbb_dep_filter,sbb_loan_filter],axis=0)\n",
    "\n",
    "################################ NEW ACCOUNT OPENINGS ###############################\n",
    "\n",
    "## SBB TAB: TOTAL ACCOUNT OPENINGS\n",
    "sbb_open_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_new_tuple)]\n",
    "sbb_open_filter=sbb_open_filter.assign(metric_name='Total New SBB Chequing Accounts')\n",
    "sbb_open_filter=filterfunc(sbb_open_filter)\n",
    "\n",
    "################################ TD SECURITIES DIRECT TRADE ###########################\n",
    "\n",
    "## SBB TAB: TOTAL TD SECURITIES DIRECT TRADE\n",
    "sbb_trade_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_trade_tuple)]\n",
    "sbb_trade_filter=sbb_trade_filter.assign(metric_name='TD Securities Direct Trade')\n",
    "sbb_trade_filter=filterfunc(sbb_trade_filter)\n",
    "\n",
    "################################ BCP WIDGETS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL BCP WIDGETS\n",
    "sbb_bcp_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_bcp_tuple)]\n",
    "sbb_bcp_filter=sbb_bcp_filter.assign(metric_name='Business Credit Protection(BCP) Widgets')\n",
    "sbb_bcp_filter=filterfunc(sbb_bcp_filter)\n",
    "\n",
    "############################# MUR MORTGAGE VOLUME######################################\n",
    "\n",
    "## SBB TAB: MUR MORTGAGE VOLUME\n",
    "sbb_mur_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_mur_tuple)]\n",
    "sbb_mur_filter=sbb_mur_filter.assign(metric_name='Total MUR Mortgage Volume')\n",
    "sbb_mur_filter=filterfunc(sbb_mur_filter)\n",
    "\n",
    "################################ WEALTH REFERRAL WIDGETS #############################\n",
    "\n",
    "## SBB TAB: WEALTH REFERRAL WIDGETS\n",
    "sbb_wealth_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_wealth_tuple)]\n",
    "sbb_wealth_filter=sbb_wealth_filter.assign(metric_name='Total Wealth Referrals')\n",
    "sbb_wealth_filter=filterfunc(sbb_wealth_filter)\n",
    "\n",
    "########################################### BODP ############################################\n",
    "\n",
    "## SBB TAB: BODP\n",
    "sbb_bodp_filter=cred_sbb_filter[cred_sbb_filter.product_code.isin(total_bodp_tuple)]\n",
    "sbb_bodp_filter=sbb_bodp_filter.assign(metric_name='Total BODP')\n",
    "sbb_bodp_filter=filterfunc(sbb_bodp_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# COUNT WIDGETS ####################################\n",
    "\n",
    "## CONCATENATE WIDGETS DATAFRAMES (GROSS SEG,CREDIT CARDS,MERCHANT,CMS,ACCOUNT OPENINGS, TD SECURITIES,BCP,WEALTH,BODP)\n",
    "psa_wid=pd.concat([cred_sbb_filter00,cc_all,merchant_all,cms_all,sbb_open_filter,sbb_trade_filter,\n",
    "                     sbb_bcp_filter,sbb_wealth_filter,sbb_bodp_filter],axis=0)\n",
    "\n",
    "##(1) group to count all metrics\n",
    "amsb_cred=psa_wid.groupby(by=['pr_acf2','employee_name','psa_month',\n",
    "                                      'metric_name','am_cost_center',\n",
    "                                      'am_cost_center_name','am_cost_center_full_name',\n",
    "                                      'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                    'elig_ind_final': 'sum'\n",
    "                     })\n",
    "amsb_cred.rename(columns = {\"elig_ind_final\":'count_segment'}, inplace = True)\n",
    "\n",
    "## create Total metric for Gross Widgets (sum of Segmentation metrics)\n",
    "##(a) subset the segmentation metrics\n",
    "cred_sbb_filter01=psa_wid[psa_wid.metric_name.isin(gross_seg_tuple)]\n",
    "\n",
    "cred_sbb_filter01['metric_name']='Total SBB Credit Widgets'\n",
    "\n",
    "amsb_seg=cred_sbb_filter01.groupby(by=['pr_acf2','employee_name','psa_month',\n",
    "                                      'metric_name','am_cost_center',\n",
    "                                      'am_cost_center_name','am_cost_center_full_name',\n",
    "                                      'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                    'elig_ind_final': 'sum'\n",
    "                     })\n",
    "amsb_seg.rename(columns = {\"elig_ind_final\":'count_segment'}, inplace = True)\n",
    "\n",
    "## concatenate the dataframes\n",
    "amsb_all99=pd.concat([amsb_cred,amsb_seg],axis=0)\n",
    "\n",
    "\n",
    "##(2) transpose data\n",
    "amsb_all90=amsb_all99.pivot_table(index=['pr_acf2','employee_name','metric_name',\n",
    "                                        'am_cost_center','am_cost_center_name',\n",
    "                                        'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "                                        'record_date'], columns=['psa_month'],\n",
    "                     values='count_segment', aggfunc='first').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# PROCESS RETAIL COMMERCIAL VOLUME FOR AMSB ################################\n",
    "## read in retail file\n",
    "df_com_fil=spark.sql(\"select * from anp_cabbtdct1_final.SCORECARD_RETAIL_FILTER where prod_nm in {}\".format(tuple(total_com_tuple)))\n",
    "df_com_volume=df_com_fil.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "df_com_volume=df_com_volume.astype({\"psa_month\": int})\n",
    "import calendar\n",
    "df_com_volume['psa_month'] = df_com_volume['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "df_com_volume.head(10)\n",
    "\n",
    "######################## CATEGORIZE between loan and deposit and total#############################################\n",
    "com_filter=df_com_volume[df_com_volume.prod_nm.isin(total_com_tuple)]\n",
    "com_filter=com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "com_filter=filterfunc(com_filter)\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "com_dep_filter=df_com_volume[df_com_volume.prod_nm.isin(com_deposit_tuple)]\n",
    "com_dep_filter=com_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "com_dep_filter=filterfunc(com_dep_filter)\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL LOAN VOLUME\n",
    "com_loan_filter=df_com_volume[df_com_volume.prod_nm.isin(com_loan_tuple)]\n",
    "com_loan_filter=com_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "com_loan_filter=filterfunc(com_loan_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all_ret=pd.concat([com_filter,com_dep_filter,com_loan_filter],axis=0)\n",
    "\n",
    "\n",
    "####################### read in buddy branch ###########################\n",
    "df_bud_max=spark.sql(\"select branch,logon,mon from \\\n",
    "(select branch,logon,cost_centre,cast(SUBSTR(record_date,5,2) as int) as mon, \\\n",
    "row_number() over(partition by logon,cast(SUBSTR(record_date,5,2) as int) order by record_date desc) as ran \\\n",
    "from anp_cabbtdct1_final.buddy_branch)b where ran=1\")\n",
    "df2=df_bud_max.withColumn(\"branch_0000\",format_string(\"%04d\",\"branch\"))\n",
    "buddy_branch=df2.toPandas()\n",
    "\n",
    "buddy_branch.head(10)\n",
    "\n",
    "## merge COM dataframe to buddy branch file\n",
    "df_retail_buddy=pd.merge(com_all_ret,buddy_branch[['branch_0000','logon']],\n",
    "                   how=\"left\",left_on=['branch_no'],right_on=['branch_0000'],indicator=True)\n",
    "\n",
    "## filter both records\n",
    "df_retail_buddy1=df_retail_buddy[(df_retail_buddy['_merge'] == 'both')]\n",
    "\n",
    "## drop logon\n",
    "df_retail_buddy1=df_retail_buddy1.drop(columns=['logon','_merge'])\n",
    "\n",
    "## keep relevant vars\n",
    "df_retail_buddy2=filterfunc(df_retail_buddy1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# SUM VOLUME ####################################\n",
    "\n",
    "## CONCATENATE VOLUME DATAFRAMES (GROSS VOLUME,COMMERCIAL VOLUME (SBB AND RETAIL), MUR VOLUME) ---THIS IS FOR AMSB ONLY\n",
    "## AM AND SM RETAIL COMMERCIAL VOLUME IS CALCULATED SEPARATELY\n",
    "psa_vol=pd.concat([gross_all,com_all,df_retail_buddy2,sbb_mur_filter],axis=0)\n",
    "\n",
    "## group to count\n",
    "psa_vol1=psa_vol.groupby(by=['pr_acf2','employee_name','psa_month','metric_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name',\n",
    "                             'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                    'current_amount': 'sum'\n",
    "                     })\n",
    "psa_vol1.rename(columns = {\"current_amount\":'vol'}, inplace = True)\n",
    "\n",
    "\n",
    "##transpose data\n",
    "psa_vol2=psa_vol1.pivot_table(index=['pr_acf2','employee_name','metric_name','am_cost_center','am_cost_center_name',\n",
    "                                     'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "                                     'record_date'], columns=['psa_month'],\n",
    "                     values='vol', aggfunc='first').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### concatenate the widgets and volume dataframes -----------THIS IS FOR AMSB ONLY (because it contains retail com vol. for amsb)\n",
    "amsb_tot=pd.concat([amsb_all90,psa_vol2],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATE ALL OF THE MONTHS\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in amsb_tot]\n",
    "\n",
    "amsb_tot.reset_index(drop=True, inplace=True)\n",
    "amsb_cred2= pd.concat([net_a[complementary], amsb_tot], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "amsb_cred2= amsb_cred2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "amsb_cred2 = amsb_cred2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "amsb_cred2.rename(columns = {\"pr_acf2\":'acf2_id'}, inplace = True)\n",
    "amsb_cred2['scorecard_filter']='SBB'\n",
    "amsb_cred2['level']='AMSB'\n",
    "\n",
    "## order relevant vars for AMSB\n",
    "amsb_cred6=amsb_cred2[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW create QTD and YTD variables\n",
    "newvarfunc(amsb_cred6)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "amsb_cred6=amsb_cred6.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_amsb_median=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_amsb_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all3=pd.merge(amsb_cred6,cred_amsb_median,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_amsb_median1=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_amsb_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all4=pd.merge(cred_amsb_all3,cred_amsb_median1,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_amsb_median2=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_amsb_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all5=pd.merge(cred_amsb_all4,cred_amsb_median2,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_amsb_median3=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_amsb_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all6=pd.merge(cred_amsb_all5,cred_amsb_median3,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_amsb_ytdmedian=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_amsb_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all7=pd.merge(cred_amsb_all6,cred_amsb_ytdmedian,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "cred_amsb_all8=cred_amsb_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "cred_amsb_all8.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP for AM (SBB FILTER)##############################\n",
    "\n",
    "#### concatenate all SBB volume dataframes (does not include retail com volume)\n",
    "psa_vol_am=pd.concat([gross_all,com_all,sbb_mur_filter],axis=0)\n",
    "\n",
    "## group to count (include acf2 because need to concatenate later with AMSB widgets df)\n",
    "psa_vol1_am=psa_vol_am.groupby(by=['pr_acf2','employee_name','psa_month','metric_name','am_cost_center',\n",
    "                             'am_cost_center_name','am_cost_center_full_name',\n",
    "                             'sm_cost_center','sm_cost_center_name','record_date'],as_index=False).aggregate({\n",
    "                    'current_amount': 'sum'\n",
    "                     })\n",
    "psa_vol1_am.rename(columns = {\"current_amount\":'vol'}, inplace = True)\n",
    "\n",
    "\n",
    "##transpose data\n",
    "psa_vol2_am=psa_vol1_am.pivot_table(index=['pr_acf2','employee_name','metric_name','am_cost_center','am_cost_center_name',\n",
    "                                     'am_cost_center_full_name','sm_cost_center','sm_cost_center_name',\n",
    "                                     'record_date'], columns=['psa_month'],\n",
    "                     values='vol', aggfunc='first').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "### concatenate the widgets and volume (does not include retail com vol.)\n",
    "psa_all_am=pd.concat([amsb_all90,psa_vol2_am],axis=0)\n",
    "\n",
    "\n",
    "########## CREATE ALL OF THE MONTHS\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in psa_all_am]\n",
    "\n",
    "psa_all_am.reset_index(drop=True, inplace=True)\n",
    "psa_all_am2= pd.concat([net_a[complementary], psa_all_am], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "psa_all_am2= psa_all_am2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "psa_all_am2 = psa_all_am2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## group by AM ##########################################\n",
    "cred_am=amgrpfunc(psa_all_am2)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_am['level']='AM'\n",
    "cred_am['scorecard_filter']='SBB'\n",
    "cred_am['acf2_id']=''\n",
    "cred_am['employee_name']=cred_am['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_am)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_am=cred_am.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_am_median=cred_am.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all3=pd.merge(cred_am,cred_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_am_median1=cred_am.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all4=pd.merge(cred_am_all3,cred_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_am_median2=cred_am.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all5=pd.merge(cred_am_all4,cred_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_am_median3=cred_am.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all6=pd.merge(cred_am_all5,cred_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_am_ytdmedian=cred_am.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all7=pd.merge(cred_am_all6,cred_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_am_all8=cred_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY SM (SBB FILTER)##############################\n",
    "cred_sm=smgrpfunc(cred_am_all8)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_sm['level']='SM'\n",
    "cred_sm['acf2_id']=''\n",
    "cred_sm['scorecard_filter']='SBB'\n",
    "cred_sm['employee_name']=cred_sm['sm_cost_center_name']\n",
    "cred_sm['am_cost_center']=''\n",
    "cred_sm['am_cost_center_name']=''\n",
    "cred_sm['am_cost_center_full_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_sm)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_sm=cred_sm.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_sm_median=cred_sm.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all3=pd.merge(cred_sm,cred_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_sm_median1=cred_sm.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all4=pd.merge(cred_sm_all3,cred_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_sm_median2=cred_sm.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all5=pd.merge(cred_sm_all4,cred_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_sm_median3=cred_sm.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all6=pd.merge(cred_sm_all5,cred_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_sm_ytdmedian=cred_sm.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all7=pd.merge(cred_sm_all6,cred_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_sm_all8=cred_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### concatenate AMSB, AM, SM\n",
    "df_sbb_all=pd.concat([cred_amsb_all8,cred_am_all8,cred_sm_all8],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "## overwrite\n",
    "#df_sbb_all.write.mode(\"overwrite\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_METRICS_SBB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(df_sbb_all).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_METRICS_SBB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
