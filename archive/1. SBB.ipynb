{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBB.py program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import HiveContext, SQLContext,SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import date,timedelta\n",
    "from datetime import datetime\n",
    "sc = SparkContext(appName = \"Combined_Table\")\n",
    "sql_context = HiveContext(sc)\n",
    "spark = SparkSession(sc)\n",
    "spark = (SparkSession.builder.enableHiveSupport().getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from numpy import nan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import format_string\n",
    "\n",
    "pd.set_option('display.width', 150)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('/home/thural2/THURAL2/thural2/record.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### FIRST PROCESS THE GROSS VOLUME SEGMENTATION METRICS###########################################\n",
    "cred_fil=spark.sql(\"select * from anp_cabbtdct1_final.psa_elig_amsb\")\n",
    "cred_sbb_filter=cred_fil.toPandas()\n",
    "\n",
    "## change psa_month to month name\n",
    "cred_sbb_filter=cred_sbb_filter.astype({\"psa_month\": int})\n",
    "import calendar\n",
    "cred_sbb_filter['psa_month'] = cred_sbb_filter['psa_month'].apply(lambda x: calendar.month_name[x]).str.lower()\n",
    "cred_sbb_filter.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsb_cred=cred_sbb_filter.groupby(by=['pr_acf2','employee_name','psa_month',\n",
    "                                      'metric_name','am_cost_center',\n",
    "                                      'am_cost_center_name','am_cost_center_full_name',\n",
    "                                      'sm_cost_center','sm_cost_center_name',\n",
    "                                      'record_date'],as_index=False).aggregate({\n",
    "                    'elig_ind_final': 'sum'\n",
    "                     })\n",
    "amsb_cred.rename(columns = {\"elig_ind_final\":'count_segment'}, inplace = True)\n",
    "\n",
    "##transpose data\n",
    "amsb_cred1=amsb_cred.pivot_table(index=['pr_acf2','employee_name','metric_name',\n",
    "                                        'am_cost_center','am_cost_center_name',\n",
    "                                        'am_cost_center_full_name',\n",
    "                                        'sm_cost_center','sm_cost_center_name',\n",
    "                                        'record_date'], columns=['psa_month'],\n",
    "                     values='count_segment', aggfunc='first').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amsb_cred1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATE ALL OF THE MONTHS\n",
    "##rename columns **************CHANGE FOR FUTURE\n",
    "cols = ['november','december','january','february','march','april','may','june','july',\n",
    "        'august','september','october']\n",
    "net_a = pd.DataFrame(list, index=['a',], columns=cols)\n",
    "\n",
    "complementary = [c for c in net_a if c not in amsb_cred1]\n",
    "\n",
    "amsb_cred1.reset_index(drop=True, inplace=True)\n",
    "amsb_cred2= pd.concat([net_a[complementary], amsb_cred1], axis=1, join='outer')\n",
    "\n",
    "##delete the extra filler row\n",
    "amsb_cred2= amsb_cred2.drop(labels='a', axis=0)\n",
    "##convert to float\n",
    "amsb_cred2 = amsb_cred2.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "amsb_cred2.rename(columns = {\"pr_acf2\":'acf2_id'}, inplace = True)\n",
    "amsb_cred2['scorecard_filter']='SBB'\n",
    "amsb_cred2['level']='AMSB'\n",
    "\n",
    "## order relevant vars for amsb_cred3\n",
    "amsb_cred3=amsb_cred2[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## also group by to get the total widgets\n",
    "amsb_cred4=amsb_cred3.groupby(by=['acf2_id','employee_name','am_cost_center',\n",
    "                                  'am_cost_center_name','am_cost_center_full_name',\n",
    "                                  'sm_cost_center','sm_cost_center_name',\n",
    "                                  'scorecard_filter','level','record_date'],as_index=False).aggregate({\n",
    "                        'november': 'sum',\n",
    "                        'december': 'sum',\n",
    "                        'january': 'sum',\n",
    "                        'february': 'sum',\n",
    "                        'march': 'sum',\n",
    "                        'april': 'sum',\n",
    "                        'may': 'sum',\n",
    "                        'june': 'sum',\n",
    "                        'july': 'sum',\n",
    "                        'august': 'sum',\n",
    "                        'september': 'sum',\n",
    "                        'october': 'sum'\n",
    "                     })\n",
    "\n",
    "amsb_cred4['metric_name']='Total SBB Credit Widgets'\n",
    "\n",
    "## order relevant vars for amsb_cred4\n",
    "amsb_cred5=amsb_cred4[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### APPEND TOTAL TO THE OTHER SUB-CATEGORIES\n",
    "amsb_cred6=pd.concat([amsb_cred5,amsb_cred3],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW create QTD and YTD variables\n",
    "newvarfunc(amsb_cred6)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "amsb_cred6=amsb_cred6.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_amsb_median=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_amsb_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all3=pd.merge(amsb_cred6,cred_amsb_median,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_amsb_median1=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_amsb_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all4=pd.merge(cred_amsb_all3,cred_amsb_median1,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_amsb_median2=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_amsb_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all5=pd.merge(cred_amsb_all4,cred_amsb_median2,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_amsb_median3=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_amsb_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all6=pd.merge(cred_amsb_all5,cred_amsb_median3,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_amsb_ytdmedian=amsb_cred6.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_amsb_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_amsb_all7=pd.merge(cred_amsb_all6,cred_amsb_ytdmedian,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "cred_amsb_all8=cred_amsb_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "cred_amsb_all8.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY AM (SBB FILTER)##############################\n",
    "cred_am=amgrpfunc(cred_amsb_all8)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_am['level']='AM'\n",
    "cred_am['scorecard_filter']='SBB'\n",
    "cred_am['acf2_id']=''\n",
    "cred_am['employee_name']=cred_am['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_am)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_am=cred_am.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_am_median=cred_am.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all3=pd.merge(cred_am,cred_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_am_median1=cred_am.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all4=pd.merge(cred_am_all3,cred_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_am_median2=cred_am.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all5=pd.merge(cred_am_all4,cred_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_am_median3=cred_am.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all6=pd.merge(cred_am_all5,cred_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_am_ytdmedian=cred_am.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_am_all7=pd.merge(cred_am_all6,cred_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_am_all8=cred_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY SM (SBB FILTER)##############################\n",
    "cred_sm=smgrpfunc(cred_am_all8)\n",
    "\n",
    "##include the LEVEL variable\n",
    "cred_sm['level']='SM'\n",
    "cred_sm['acf2_id']=''\n",
    "cred_sm['scorecard_filter']='SBB'\n",
    "cred_sm['employee_name']=cred_sm['sm_cost_center_name']\n",
    "cred_sm['am_cost_center']=''\n",
    "cred_sm['am_cost_center_name']=''\n",
    "cred_sm['am_cost_center_full_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(cred_sm)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "cred_sm=cred_sm.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "cred_sm_median=cred_sm.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "cred_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all3=pd.merge(cred_sm,cred_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "cred_sm_median1=cred_sm.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "cred_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all4=pd.merge(cred_sm_all3,cred_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "cred_sm_median2=cred_sm.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "cred_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all5=pd.merge(cred_sm_all4,cred_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "cred_sm_median3=cred_sm.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "cred_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all6=pd.merge(cred_sm_all5,cred_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "cred_sm_ytdmedian=cred_sm.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "cred_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "cred_sm_all7=pd.merge(cred_sm_all6,cred_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "cred_sm_all8=cred_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "############################# NOW PROCESS PSA METRICS ################################\n",
    "## spark sql\n",
    "df_fil=spark.sql(\"select * from anp_cabbtdct1_final.SCORECARD_SBB_FILTER\")\n",
    "mif_sbb_filter=df_fil.toPandas()\n",
    "mif_sbb_filter.head(10)\n",
    "\n",
    "## rename the numeric months to full month name\n",
    "mif_sbb_filter.rename(columns = {'month11':'november', 'month12': 'december',\n",
    "                       'month1':'january','month2': 'february', 'month3':'march', 'month4': 'april',\n",
    "                       'month5':'may', 'month6': 'june','month7':'july', 'month8': 'august',\n",
    "                       'month9':'september', 'month10': 'october'}, inplace = True)\n",
    "\n",
    "##convert to float\n",
    "mif_sbb_filter = mif_sbb_filter.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "## filter out VOLUME\n",
    "df_mif_volume=mif_sbb_filter[(mif_sbb_filter.bal_typ=='BM') & (mif_sbb_filter.sub_typ=='A')]\n",
    "\n",
    "## filter out WIDGETS\n",
    "df_mif_widgets=mif_sbb_filter[(mif_sbb_filter.bal_typ=='BM') & (mif_sbb_filter.sub_typ=='B')]\n",
    "\n",
    "############################# GROSS VOLUME ###########################################\n",
    "## SBB TAB: TOTAL SBB GROSS VOLUME\n",
    "sbb_gross_filter=df_mif_volume[df_mif_volume.prod_nm.isin(gross_all_tuple)]\n",
    "sbb_gross_filter=sbb_gross_filter.assign(metric_name='Total SBB Gross Volume')\n",
    "sbb_gross_filter=filterfunc(sbb_gross_filter)\n",
    "\n",
    "## SBB GROSS LOC VOLUME\n",
    "gross_loc_filter=df_mif_volume[df_mif_volume.prod_nm.isin(gross_loc_tuple)]\n",
    "gross_loc_filter=gross_loc_filter.assign(metric_name='SBB Gross LOC Volume')\n",
    "gross_loc_filter=filterfunc(gross_loc_filter)\n",
    "\n",
    "## SBB GROSS LON VOLUME\n",
    "gross_lon_filter=df_mif_volume[df_mif_volume.prod_nm.isin(gross_lon_tuple)]\n",
    "gross_lon_filter=gross_lon_filter.assign(metric_name='SBB Gross LON Volume')\n",
    "gross_lon_filter=filterfunc(gross_lon_filter)\n",
    "\n",
    "## SBB GROSS PROFESSIONAL STUDENT LOC VOLUME\n",
    "gross_prof_filter=df_mif_volume[df_mif_volume.prod_nm.isin(gross_student_loc_tuple)]\n",
    "gross_prof_filter=gross_prof_filter.assign(metric_name='Gross Professional Student LOC')\n",
    "gross_prof_filter=filterfunc(gross_prof_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "gross_all=pd.concat([sbb_gross_filter,gross_loc_filter,gross_lon_filter,gross_prof_filter],axis=0)\n",
    "\n",
    "########################## CREDIT CARDS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL CREDIT CARDS\n",
    "sbb_cc_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_cc_tuple)]\n",
    "sbb_cc_filter=sbb_cc_filter.assign(metric_name='Total Credit Cards')\n",
    "sbb_cc_filter=filterfunc(sbb_cc_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_bv_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(business_visa_cc_tuple)]\n",
    "sbb_bv_filter=sbb_bv_filter.assign(metric_name='Credit Cards - Business VISA')\n",
    "sbb_bv_filter=filterfunc(sbb_bv_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS VISA\n",
    "sbb_btv_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(business_travel_tuple)]\n",
    "sbb_btv_filter=sbb_btv_filter.assign(metric_name='Credit Cards - Business Travel VISA')\n",
    "sbb_btv_filter=filterfunc(sbb_btv_filter)\n",
    "\n",
    "## SBB TAB: AEROPLAN BUSINESS\n",
    "sbb_aero_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(business_aero_tuple)]\n",
    "sbb_aero_filter=sbb_aero_filter.assign(metric_name='Credit Cards - Aeroplan Business')\n",
    "sbb_aero_filter=filterfunc(sbb_aero_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT NO FEE\n",
    "sbb_nofee_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(bus_nofee_tuple)]\n",
    "sbb_nofee_filter=sbb_nofee_filter.assign(metric_name='Credit Cards - Business Select No Fee')\n",
    "sbb_nofee_filter=filterfunc(sbb_nofee_filter)\n",
    "\n",
    "## SBB TAB: BUSINESS SELECT FEE\n",
    "sbb_fee_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(bus_fee_tuple)]\n",
    "sbb_fee_filter=sbb_fee_filter.assign(metric_name='Credit Cards - Business Select Fee')\n",
    "sbb_fee_filter=filterfunc(sbb_fee_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "cc_all=pd.concat([sbb_cc_filter,sbb_bv_filter,sbb_btv_filter,sbb_aero_filter,\n",
    "                  sbb_nofee_filter,sbb_fee_filter],axis=0)\n",
    "\n",
    "########################## MERCHANT SOLUTIONS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL MERCHANT SOLUTIONS\n",
    "merchant_all=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_mer_tuple)]\n",
    "merchant_all=merchant_all.assign(metric_name='Total Merchant Solutions')\n",
    "merchant_all=filterfunc(merchant_all)\n",
    "\n",
    "################################ CMS ###############################################\n",
    "\n",
    "## SBB TAB: TOTAL CMS\n",
    "cms_all=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_cms_tuple)]\n",
    "cms_all=cms_all.assign(metric_name='Total Cash Management Services (including RDC)')\n",
    "cms_all=filterfunc(cms_all)\n",
    "\n",
    "################################ COMMERCIAL VOLUME ###################################\n",
    "\n",
    "## SBB TAB: TOTAL COMMERCIAL VOLUME\n",
    "sbb_com_filter=df_mif_volume[df_mif_volume.prod_nm.isin(total_com_tuple)]\n",
    "sbb_com_filter=sbb_com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "sbb_com_filter=filterfunc(sbb_com_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "sbb_dep_filter=df_mif_volume[df_mif_volume.prod_nm.isin(com_deposit_tuple)]\n",
    "sbb_dep_filter=sbb_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "sbb_dep_filter=filterfunc(sbb_dep_filter)\n",
    "\n",
    "## SBB TAB: COMMERCIAL LOAN VOLUME\n",
    "sbb_loan_filter=df_mif_volume[df_mif_volume.prod_nm.isin(com_loan_tuple)]\n",
    "sbb_loan_filter=sbb_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "sbb_loan_filter=filterfunc(sbb_loan_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all=pd.concat([sbb_com_filter,sbb_dep_filter,sbb_loan_filter],axis=0)\n",
    "\n",
    "################################ NEW ACCOUNT OPENINGS ###############################\n",
    "\n",
    "## SBB TAB: TOTAL ACCOUNT OPENINGS\n",
    "sbb_open_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_new_tuple)]\n",
    "sbb_open_filter=sbb_open_filter.assign(metric_name='Total New SBB Chequing Accounts')\n",
    "sbb_open_filter=filterfunc(sbb_open_filter)\n",
    "\n",
    "################################ TD SECURITIES DIRECT TRADE ###########################\n",
    "\n",
    "## SBB TAB: TOTAL TD SECURITIES DIRECT TRADE\n",
    "sbb_trade_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_trade_tuple)]\n",
    "sbb_trade_filter=sbb_trade_filter.assign(metric_name='TD Securities Direct Trade')\n",
    "sbb_trade_filter=filterfunc(sbb_trade_filter)\n",
    "\n",
    "################################ BCP WIDGETS ##########################################\n",
    "\n",
    "## SBB TAB: TOTAL BCP WIDGETS\n",
    "sbb_bcp_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_bcp_tuple)]\n",
    "sbb_bcp_filter=sbb_bcp_filter.assign(metric_name='Business Credit Protection(BCP) Widgets')\n",
    "sbb_bcp_filter=filterfunc(sbb_bcp_filter)\n",
    "\n",
    "############################# MUR MORTGAGE VOLUME######################################\n",
    "\n",
    "## SBB TAB: MUR MORTGAGE VOLUME\n",
    "sbb_mur_filter=df_mif_volume[df_mif_volume.prod_nm.isin(total_mur_tuple)]\n",
    "sbb_mur_filter=sbb_mur_filter.assign(metric_name='Total MUR Mortgage Volume')\n",
    "sbb_mur_filter=filterfunc(sbb_mur_filter)\n",
    "\n",
    "################################ WEALTH REFERRAL WIDGETS #############################\n",
    "\n",
    "## SBB TAB: WEALTH REFERRAL WIDGETS\n",
    "sbb_wealth_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_wealth_tuple)]\n",
    "sbb_wealth_filter=sbb_wealth_filter.assign(metric_name='Total Wealth Referrals')\n",
    "sbb_wealth_filter=filterfunc(sbb_wealth_filter)\n",
    "\n",
    "########################################### BODP ############################################\n",
    "\n",
    "## SBB TAB: BODP\n",
    "sbb_bodp_filter=df_mif_widgets[df_mif_widgets.prod_nm.isin(total_bodp_tuple)]\n",
    "sbb_bodp_filter=sbb_bodp_filter.assign(metric_name='Total BODP')\n",
    "sbb_bodp_filter=filterfunc(sbb_bodp_filter)\n",
    "\n",
    "############################ CONCATENATE ALL DATAFRAMES ###############################\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS (exclude commercial - will process separately for AMSB)\n",
    "psa_all=pd.concat([gross_all,cc_all,merchant_all,cms_all, \n",
    "                   sbb_open_filter,sbb_trade_filter,sbb_bcp_filter,\n",
    "                   sbb_mur_filter,sbb_wealth_filter,sbb_bodp_filter],axis=0)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS (includes commercial for AM/SM rollup)\n",
    "psa_all99=pd.concat([gross_all,cc_all,merchant_all,cms_all, com_all,\n",
    "                   sbb_open_filter,sbb_trade_filter,sbb_bcp_filter,\n",
    "                   sbb_mur_filter,sbb_wealth_filter,sbb_bodp_filter],axis=0)\n",
    "\n",
    "psa_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# PROCESS COMMERCIAL VOLUME FOR AMSB ################################\n",
    "## read in retail file\n",
    "## spark sql\n",
    "df_com_fil=spark.sql(\"select * from anp_cabbtdct1_final.SCORECARD_RETAIL_FILTER where prod_nm in {}\".format(tuple(total_com_tuple)))\n",
    "mif_com_filter=df_com_fil.toPandas()\n",
    "\n",
    "## rename the numeric months to full month name\n",
    "mif_com_filter.rename(columns = {'month11':'november', 'month12': 'december',\n",
    "                       'month1':'january','month2': 'february', 'month3':'march', 'month4': 'april',\n",
    "                       'month5':'may', 'month6': 'june','month7':'july', 'month8': 'august',\n",
    "                       'month9':'september', 'month10': 'october'}, inplace = True)\n",
    "\n",
    "##convert to float\n",
    "mif_com_filter = mif_com_filter.astype({'november': float,'december': float,\n",
    "                                'january': float, 'february': float, 'march': float,\n",
    "                                'april': float, 'may': float,'june':float,'july': float,\n",
    "                                'august': float, 'september':float,'october': float})\n",
    "\n",
    "## filter out VOLUME\n",
    "df_com_volume=mif_com_filter[(mif_com_filter.bal_typ=='BM') & (mif_com_filter.sub_typ=='A')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## CATEGORIZE between loan and deposit and total#############################################\n",
    "\n",
    "com_filter=df_com_volume[df_com_volume.prod_nm.isin(total_com_tuple)]\n",
    "com_filter=com_filter.assign(metric_name='ALL Total Commercial Volume')\n",
    "com_filter=filterfunc(com_filter)\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL DEPOSIT VOLUME\n",
    "com_dep_filter=df_com_volume[df_com_volume.prod_nm.isin(com_deposit_tuple)]\n",
    "com_dep_filter=com_dep_filter.assign(metric_name='All Commercial Deposit Volume')\n",
    "com_dep_filter=filterfunc(com_dep_filter)\n",
    "\n",
    "## RETAIL TAB: COMMERCIAL LOAN VOLUME\n",
    "com_loan_filter=df_com_volume[df_com_volume.prod_nm.isin(com_loan_tuple)]\n",
    "com_loan_filter=com_loan_filter.assign(metric_name='All Commercial Loan Volume')\n",
    "com_loan_filter=filterfunc(com_loan_filter)\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS\n",
    "com_all_ret=pd.concat([com_filter,com_dep_filter,com_loan_filter],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in latest buddy branch table\n",
    "df_bud_max=spark.sql(\"select max(record_date) as max_rec from anp_cabbtdct1_final.buddy_branch\")\n",
    "df1 = spark.table('anp_cabbtdct1_final.BUDDY_BRANCH')\n",
    "df2=df1.withColumn(\"branch_0000\",format_string(\"%04d\",\"branch\"))\n",
    "df3 = df2.join(df_bud_max, how='inner', on= F.col('record_date')==F.col('max_rec'))\n",
    "buddy_branch=df3.toPandas()\n",
    "\n",
    "## merge COM dataframe to buddy branch file\n",
    "df_retail_buddy=pd.merge(com_all_ret,buddy_branch[['branch_0000','logon']],\n",
    "                   how=\"left\",left_on=['branch_no'],right_on=['branch_0000'],indicator=True)\n",
    "\n",
    "## filter both records\n",
    "df_retail_buddy1=df_retail_buddy[(df_retail_buddy['_merge'] == 'both')]\n",
    "\n",
    "## drop 'employee_name' --this is blank because it's a retail employee\n",
    "df_retail_buddy1=df_retail_buddy1.drop(columns=['employee_name','acf2_id','_merge'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retail_buddy1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# MERGE THE RETAIL FILTER TO HRM_SBB_ALIGNMENT TO GET 'EMPLOYEE_NAME' #############################\n",
    "sbb_hr = spark.table('anp_cabbtdct1_final.hrm_sbb_alignment')\n",
    "sbb_hr1=sbb_hr.toPandas()\n",
    "\n",
    "## select most recent record date\n",
    "sbb_hr1=sbb_hr1[(sbb_hr1.record_date==rec_date)]\n",
    "\n",
    "## merge retail filter to hrm file\n",
    "retail_fil_amsb=pd.merge(df_retail_buddy1,sbb_hr1[['acf2_id','employee_name']],\n",
    "                   how=\"left\",left_on=['logon'],right_on=['acf2_id'],indicator=True)\n",
    "\n",
    "### filter only AMSBs; there could also be AMs who did sales but won't be picked up now; pick up in rollup\n",
    "retail_fil_amsb1=retail_fil_amsb[(retail_fil_amsb['_merge'] == 'both')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_fil_amsb1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## CONCATENATE THE SBB AND RETAIL FILTERS FOR COMMERCIAL ##############################\n",
    "\n",
    "## SBB filter: keep relevant vars\n",
    "com_all1=filterfunc(com_all)\n",
    "\n",
    "## RETAIL filter: keep relevant vars and rename logon to acf2_id\n",
    "df_retail_buddy2=retail_fil_amsb[['metric_name','key_typ','logon','year','prod_nm','bal_typ',\n",
    "                 'sub_typ','branch_no','wk_tot', 'november','december',\n",
    "                 'january','february','march','april','may','june','july','august',\n",
    "                 'september','october','period_end_date','employee_name',\n",
    "                 'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "                 'sm_cost_center','sm_cost_center_name','record_date']]\n",
    "\n",
    "##rename logon to acf2_id\n",
    "df_retail_buddy2.rename(columns={\"logon\":'acf2_id'}, inplace = True)\n",
    "df_retail_buddy2=filterfunc(df_retail_buddy2)\n",
    "\n",
    "## concatenate amsb (sbb) and amsb (retail) for commercial\n",
    "com_all_amsb=pd.concat([com_all1,df_retail_buddy2],axis=0)\n",
    "\n",
    "## concatenate the commercial dataframe to the rest of the metrics (excluding commercial)\n",
    "psa_amsb=pd.concat([psa_all,com_all_amsb],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################  GROUP BY AMSB FOR ALL METRICS (based on SM region) ##########################################\n",
    "psa_amsb=grpfunc(psa_amsb)\n",
    "                        \n",
    "##include the LEVEL variable\n",
    "psa_amsb['level']='AMSB'\n",
    "psa_amsb['scorecard_filter']='SBB'\n",
    "\n",
    "##CREATE THE AMSB QUARTER AND YTD VARIABLES\n",
    "newvarfunc(psa_amsb)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "psa_amsb=psa_amsb.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_amsb_median=psa_amsb.groupby(['metric_name','sm_cost_center'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_amsb_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_amsb_all3=pd.merge(psa_amsb,psa_amsb_median,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_amsb_median1=psa_amsb.groupby(['metric_name','sm_cost_center'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_amsb_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_amsb_all4=pd.merge(psa_amsb_all3,psa_amsb_median1,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_amsb_median2=psa_amsb.groupby(['metric_name','sm_cost_center'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_amsb_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_amsb_all5=pd.merge(psa_amsb_all4,psa_amsb_median2,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_amsb_median3=psa_amsb.groupby(['metric_name','sm_cost_center'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_amsb_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_amsb_all6=pd.merge(psa_amsb_all5,psa_amsb_median3,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_amsb_ytdmedian=psa_amsb_all6.groupby(['metric_name','sm_cost_center'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_amsb_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_amsb_all7=pd.merge(psa_amsb_all6,psa_amsb_ytdmedian,on=['metric_name','sm_cost_center'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_amsb_all8=psa_amsb_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY AM (SBB FILTER)##############################\n",
    "psa_am=amgrpfunc(psa_all99)\n",
    "\n",
    "##include the LEVEL variable\n",
    "psa_am['level']='AM'\n",
    "psa_am['scorecard_filter']='SBB'\n",
    "psa_am['acf2_id']=''\n",
    "psa_am['employee_name']=psa_am['am_cost_center_full_name']\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(psa_am)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "psa_am=psa_am.replace(0.0, np.nan)\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_am_median=psa_am.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_am_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all3=pd.merge(psa_am,psa_am_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_am_median1=psa_am.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_am_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all4=pd.merge(psa_am_all3,psa_am_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_am_median2=psa_am.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_am_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all5=pd.merge(psa_am_all4,psa_am_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_am_median3=psa_am.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_am_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all6=pd.merge(psa_am_all5,psa_am_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_am_ytdmedian=psa_am.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_am_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_am_all7=pd.merge(psa_am_all6,psa_am_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_am_all8=psa_am_all7[['metric_name','level','acf2_id','employee_name',\n",
    "               'november','december','january','february','march','april','may','june','july',\n",
    "               'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  GROUP BY SM (SBB FILTER)##############################\n",
    "psa_sm=smgrpfunc(psa_am)\n",
    "\n",
    "##include the LEVEL variable\n",
    "psa_sm['level']='SM'\n",
    "psa_sm['acf2_id']=''\n",
    "psa_sm['scorecard_filter']='SBB'\n",
    "psa_sm['employee_name']=psa_sm['sm_cost_center_name']\n",
    "psa_sm['am_cost_center']=''\n",
    "psa_sm['am_cost_center_name']=''\n",
    "psa_sm['am_cost_center_full_name']=''\n",
    "\n",
    "##CREATE THE AM QUARTER AND YTD VARIABLES\n",
    "newvarfunc(psa_sm)\n",
    "\n",
    "## replace 0 with NaN so median only counts non-zeros\n",
    "psa_sm=psa_sm.replace(0.0, np.nan)\n",
    "\n",
    "\n",
    "## CREATE THE QTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "## Q1\n",
    "psa_sm_median=psa_sm.groupby(['metric_name'], as_index=False)['q1'].median()\n",
    "##rename median\n",
    "psa_sm_median.rename(columns = {'q1':'q1_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all3=pd.merge(psa_sm,psa_sm_median,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q2\n",
    "psa_sm_median1=psa_sm.groupby(['metric_name'], as_index=False)['q2'].median()\n",
    "##rename median\n",
    "psa_sm_median1.rename(columns = {'q2':'q2_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all4=pd.merge(psa_sm_all3,psa_sm_median1,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q3\n",
    "psa_sm_median2=psa_sm.groupby(['metric_name'], as_index=False)['q3'].median()\n",
    "##rename median\n",
    "psa_sm_median2.rename(columns = {'q3':'q3_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all5=pd.merge(psa_sm_all4,psa_sm_median2,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## Q4\n",
    "psa_sm_median3=psa_sm.groupby(['metric_name'], as_index=False)['q4'].median()\n",
    "##rename median\n",
    "psa_sm_median3.rename(columns = {'q4':'q4_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all6=pd.merge(psa_sm_all5,psa_sm_median3,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "\n",
    "## CREATE THE YTD BENCHMARK (\"quarter\" is a set variable (current))\n",
    "psa_sm_ytdmedian=psa_sm.groupby(['metric_name'], as_index=False)['ytd'].median()\n",
    "##rename median\n",
    "psa_sm_ytdmedian.rename(columns = {'ytd':'ytd_benchmark'}, inplace = True)\n",
    "### merge to dataframe\n",
    "psa_sm_all7=pd.merge(psa_sm_all6,psa_sm_ytdmedian,on=['metric_name'],\n",
    "                   how=\"left\")\n",
    "\n",
    "## keep relevant vars\n",
    "psa_sm_all8=psa_sm_all7[['metric_name','level','acf2_id','employee_name',\n",
    "                'november','december','january','february','march','april','may','june','july',\n",
    "                'august','september','october','q1','q1_benchmark','q2','q2_benchmark','q3',\n",
    "               'q3_benchmark','q4','q4_benchmark','ytd','ytd_benchmark',\n",
    "               'am_cost_center','am_cost_center_name','am_cost_center_full_name',\n",
    "               'sm_cost_center','sm_cost_center_name','scorecard_filter','record_date']]\n",
    "\n",
    "\n",
    "### the 3 dataframes (AMSB, AM, SM) have aggregated month1-month12 and q1-q4,ytd\n",
    "\n",
    "### APPEND ALL THE DATAFRAME FILTERS including the segmentation metrics\n",
    "df_sbb_all=pd.concat([psa_amsb_all8,psa_am_all8,psa_sm_all8,\n",
    "                      cred_amsb_all8,cred_am_all8,cred_sm_all8],axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sbb_all.metric_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "## overwrite\n",
    "#df_sbb_all.write.mode(\"overwrite\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_METRICS_SBB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert pandas dataframe to Pyspark dataframe and save in table\n",
    "spark.sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n",
    "spark.createDataFrame(df_sbb_all).write.mode(\"append\").partitionBy(\"record_date\").format(\"hive\").saveAsTable(\"anp_cabbtdct1_final.SBB_SC_METRICS_SBB\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
